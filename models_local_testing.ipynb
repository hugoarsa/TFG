{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing\n",
    "\n",
    "Now that all the metadata has been studied some testing with models from diferent sources and original code will be undergone in order to define some models to send to the boada environment.\n",
    "\n",
    "We will start slow with simple pre-trained models extracted directly from the pytorch environment and build from those up with the modifications that we want to study in the experimentation. Mainly the models tested will be ResNet (in some of it's variants) and some DensNet variants at first with the option of further models if everything goes to plan.\n",
    "\n",
    "Another objective would be to try to test the difference between transfer learning and full training from scratch, considering some other more sophisticated learning methods like one-shot if there is time.\n",
    "\n",
    "Finally some degree of localization will be accquired with the advancements of the paper from Selvaraju et al. of Grad-CAM.  Code will be recicled with the original paper code with the necessary modifications in order to apply it to the selected models of the project.\n",
    "\n",
    "\n",
    "## Preparing the split between test, train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Get the labels and read the original metadata\n",
    "labels = ['Atelectasis',\n",
    "          'Cardiomegaly',\n",
    "          'Consolidation',\n",
    "          'Edema',\n",
    "          'Effusion',\n",
    "          'Emphysema',\n",
    "          'Fibrosis',\n",
    "          'Hernia',\n",
    "          'Infiltration',\n",
    "          'Mass',\n",
    "          'Nodule',\n",
    "          'Pleural_Thickening',\n",
    "          'Pneumonia',\n",
    "          'Pneumothorax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('Data_Entry_2017_v2020.csv', delimiter=',')\n",
    "\n",
    "# Encode the labels with multi-label friendly encoding\n",
    "for label in labels:\n",
    "    metadata[label] = metadata['Finding Labels'].apply(lambda x: 1 if label in x else 0)\n",
    "\n",
    "metadata_positive = metadata[metadata['Finding Labels'] != 'No Finding']\n",
    "\n",
    "metadata = metadata.drop(columns=['Finding Labels', 'Follow-up #','Patient Age', 'Patient Gender', 'View Position', 'OriginalImage[Width','Height]', 'OriginalImagePixelSpacing[x', 'y]'])\n",
    "\n",
    "# Get the test train and val splits according to the patient ID so no patients end up split between groups\n",
    "gss_test = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
    "train_val_idx, test_idx = next(gss_test.split(metadata, groups=metadata['Patient ID']))\n",
    "\n",
    "train_val_metadata = metadata.iloc[train_val_idx]\n",
    "test_metadata = metadata.iloc[test_idx]\n",
    "\n",
    "gss_train_val = GroupShuffleSplit(test_size=0.125, n_splits=1, random_state=42)\n",
    "train_idx, val_idx = next(gss_train_val.split(train_val_metadata, groups=train_val_metadata['Patient ID']))\n",
    "\n",
    "train_metadata = train_val_metadata.iloc[train_idx]\n",
    "val_metadata = train_val_metadata.iloc[val_idx]\n",
    "\n",
    "\n",
    "# Drop the column of patient ID\n",
    "train_metadata = train_metadata.drop(columns=['Patient ID'])\n",
    "val_metadata = val_metadata.drop(columns=['Patient ID'])\n",
    "test_metadata = test_metadata.drop(columns=['Patient ID'])\n",
    "\n",
    "#Write all the new metadata as csv to load easier\n",
    "train_metadata.to_csv('./labels/train_metadata.csv', index=False)\n",
    "val_metadata.to_csv('./labels/val_metadata.csv', index=False)\n",
    "test_metadata.to_csv('./labels/test_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_positive.reset_index(drop=True, inplace=True)\n",
    "\n",
    "metadata_positive = metadata_positive.drop(columns=['Finding Labels', 'Follow-up #','Patient Age', 'Patient Gender', 'View Position', 'OriginalImage[Width','Height]', 'OriginalImagePixelSpacing[x', 'y]'])\n",
    "\n",
    "train_val_idx, test_idx = next(gss_test.split(metadata_positive, groups=metadata_positive['Patient ID']))\n",
    "\n",
    "train_val_metadata_p = metadata_positive.iloc[train_val_idx]\n",
    "test_metadata_p = metadata_positive.iloc[test_idx]\n",
    "\n",
    "train_idx, val_idx = next(gss_train_val.split(train_val_metadata_p, groups=train_val_metadata_p['Patient ID']))\n",
    "\n",
    "train_metadata_p = train_val_metadata_p.iloc[train_idx]\n",
    "val_metadata_p = train_val_metadata_p.iloc[val_idx]\n",
    "\n",
    "\n",
    "# Drop the column of patient ID\n",
    "train_metadata_p = train_metadata_p.drop(columns=['Patient ID'])\n",
    "val_metadata_p = val_metadata_p.drop(columns=['Patient ID'])\n",
    "test_metadata_p = test_metadata_p.drop(columns=['Patient ID'])\n",
    "\n",
    "\n",
    "#Write all the new metadata as csv to load easier\n",
    "train_metadata_p.to_csv('./labels/train_metadata_positive.csv', index=False)\n",
    "val_metadata_p.to_csv('./labels/val_metadata_positive.csv', index=False)\n",
    "test_metadata_p.to_csv('./labels/test_metadata_positive.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in terms of positives train: 36350, val: 5116, test: 10293 and total: 51759\n",
      "in terms of all train: 78873, val: 10953, test: 22294 and total: 112120\n"
     ]
    }
   ],
   "source": [
    "print(f'in terms of positives train: {len(train_metadata_p)}, val: {len(val_metadata_p)}, test: {len(test_metadata_p)} and total: {len(train_metadata_p) + len(test_metadata_p) + len(val_metadata_p) }')\n",
    "\n",
    "print(f'in terms of all train: {len(train_metadata)}, val: {len(val_metadata)}, test: {len(test_metadata)} and total: {len(train_metadata) + len(test_metadata) + len(val_metadata) }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset definition and load (dataset.py)\n",
    "\n",
    "We define the dataset and load from the data entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "class ChestXRay(Dataset):\n",
    "    def __init__(self, df_dir, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df_dir: Path to the csv file with image names and labels.\n",
    "            image_dir: Directory with all the images with the labels.\n",
    "            transform: Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(df_dir)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.size = len(self.data_frame)\n",
    "        self.labels = np.array(self.data_frame.iloc[:, 1:])\n",
    "        self.images = self.data_frame.iloc[:,0]\n",
    "\n",
    "        #cambiar esta mier\n",
    "        self.pred_label =  {'Atelectasis': 0,\n",
    "                            'Cardiomegaly': 1,\n",
    "                            'Consolidation': 2,\n",
    "                            'Edema': 3,\n",
    "                            'Effusion': 4,\n",
    "                            'Emphysema': 5,\n",
    "                            'Fibrosis': 6,\n",
    "                            'Hernia': 7,\n",
    "                            'Infiltration': 8,\n",
    "                            'Mass': 9,\n",
    "                            'Nodule': 10,\n",
    "                            'Pleural_Thickening': 11,\n",
    "                            'Pneumonia': 12,\n",
    "                            'Pneumothorax': 13}\n",
    "        \n",
    "        self.classes = ['Atelectasis',\n",
    "                        'Cardiomegaly',\n",
    "                        'Consolidation',\n",
    "                        'Edema',\n",
    "                        'Effusion',\n",
    "                        'Emphysema',\n",
    "                        'Fibrosis',\n",
    "                        'Hernia',\n",
    "                        'Infiltration',\n",
    "                        'Mass',\n",
    "                        'Nodule',\n",
    "                        'Pleural_Thickening',\n",
    "                        'Pneumonia',\n",
    "                        'Pneumothorax']\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image path\n",
    "        img_name = os.path.join(self.image_dir, self.images.iloc[idx])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        \n",
    "        # Get labels\n",
    "        labels = np.array(self.labels[idx])\n",
    "        \n",
    "        # Check for any object types (invalid data)\n",
    "        if not np.issubdtype(labels.dtype, np.number):\n",
    "            raise TypeError(f\"Non-numeric label detected at index {idx}: {labels}\")\n",
    "        \n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        image = np.array(image)\n",
    "        \n",
    "        return {'image': image, 'labels': labels}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various functions (utils.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "def make_data_loaders(train_csv,val_csv,image_dir,batch_size,image_size):\n",
    "    \n",
    "\n",
    "    train_transforms = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "    ])\n",
    "\n",
    "    val_transforms = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "    ])\n",
    "\n",
    "    train_dataset = ChestXRay(df_dir=train_csv, image_dir=image_dir, transform=train_transforms)\n",
    "    val_dataset = ChestXRay(df_dir=val_csv, image_dir=image_dir, transform=val_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "\n",
    "    return dataloaders, {'train':len(train_dataset),'val':len(train_dataset)}, train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "def LoadModel(checkpoint_file, model, optimizer, epoch_inti, best_auc_ave, num_GPU):\n",
    "    '''\n",
    "    The loads the model, optimizer, current epoch, and current validation AUC from the checkpoint location provided.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    checkpoint_file: (str) the location of the model in s/m\n",
    "    model: PyTorch model\n",
    "    optimizer: PyTorch optimizer\n",
    "    epoch_inti: current epoch\n",
    "    best_auc_ave: current best AUC\n",
    "    num_GPU : (int) number of GPUs that are being used\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Returns the model, optimizer, epoch_inti, best_auc_ave from the saved location.\n",
    "    '''\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    epoch_inti = checkpoint['epoch']\n",
    "    best_auc_ave = checkpoint['best_va_acc']\n",
    "    if num_GPU > 1:\n",
    "        model.module.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return model, optimizer, epoch_inti, best_auc_ave\n",
    "\n",
    "\n",
    "def SaveModel(epoch, model, optimizer, best_auc_ave, file_name, num_GPU):\n",
    "    \"\"\"\n",
    "    Save the model parameters, optimizer, best_AUC\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch : (int) current epoch\n",
    "    model : Pytorch model to save\n",
    "    optimizer : Pytorch optimzer to save\n",
    "    best_auc_ave : (float) current best AUC\n",
    "    file_name : (str) location where the model needed to be saved\n",
    "    num_GPU : (int) number of GPUs that are being used\n",
    "\n",
    "    \"\"\"\n",
    "    if num_GPU > 1:\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.module.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'best_va_acc': best_auc_ave\n",
    "        }\n",
    "    else:\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'best_va_acc': best_auc_ave\n",
    "        }\n",
    "    torch.save(state, file_name)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adadelta, Adagrad, Adam, RMSprop\n",
    "\n",
    "def get_optimizer(params, optimizer, lr=1e-4, momentum=0.9, weight_decay=0.0):\n",
    "    \"\"\"\n",
    "    Loads and returns the optimizer.\n",
    "    \"\"\"\n",
    "    if optimizer == 'SGD':\n",
    "        return SGD(params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    elif optimizer == 'Adadelta':\n",
    "        return Adadelta(params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer == 'Adagrad':\n",
    "        return Adagrad(params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer == 'Adam':\n",
    "        return Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        return RMSprop(params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise Exception('Unknown optimizer : {}'.format(optimizer))\n",
    "\n",
    "\n",
    "def weighted_BCELoss(output, target, weights=None):\n",
    "    '''\n",
    "    The function computes the weighted Binary cross Entropy loss.\n",
    "    Parameters\n",
    "    ----------\n",
    "    output :  Predicted value from model. (tensor NX8 for multi-label classifcation or Nx1 for binary classification.)\n",
    "    target : (tensor) Ground truth label. (tensor NX8 for multi-label classifcation or Nx1 for binary classification.)\n",
    "    weights : the weights (float tensor)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : the WBCE in float tensor\n",
    "    '''\n",
    "    output = output.clamp(min=1e-5, max=1 - 1e-5)\n",
    "    target = target.float()\n",
    "    if weights is not None:\n",
    "        assert len(weights) == 2\n",
    "        loss = -weights[0] * (target * torch.log(output)) - weights[1] * ((1 - target) * torch.log(1 - output))\n",
    "    else:\n",
    "        loss = -target * torch.log(output) - (1 - target) * torch.log(1 - output)\n",
    "    return torch.sum(loss)\n",
    "\n",
    "def lr_schedule(lr, lr_factor, epoch_now, lr_epochs):\n",
    "    \"\"\"\n",
    "    Learning rate schedule with respect to epoch\n",
    "    lr: float, initial learning rate\n",
    "    lr_factor: float, decreasing factor every epoch_lr\n",
    "    epoch_now: int, the current epoch\n",
    "    lr_epochs: list of int, decreasing every epoch in lr_epochs\n",
    "    return: lr, float, scheduled learning rate.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for epoch in lr_epochs:\n",
    "        if epoch_now >= epoch:\n",
    "            count += 1\n",
    "            continue\n",
    "        break\n",
    "    return lr * np.power(lr_factor, count)\n",
    "\n",
    "\n",
    "def get_loss(output, target, index, device, cfg):\n",
    "    target = target[:, index].view(-1)\n",
    "    if target.sum() == 0:\n",
    "        loss = torch.tensor(0., requires_grad=True).to(device)\n",
    "    else:\n",
    "        weight = (target.size()[0] - target.sum()) / target.sum()\n",
    "        loss = F.binary_cross_entropy_with_logits(\n",
    "            output[:, index].view(-1), target.float(), pos_weight=weight)\n",
    "    label = torch.sigmoid(output[:, index].view(-1)).ge(0.5).float()\n",
    "    acc = (target == label).float().sum() / len(label)\n",
    "    return (loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training method and validation of training\n",
    "\n",
    "Basic training method based on epochs and iterating through all the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_save_dir = './saves'\n",
    "image_dir = './resized_images'\n",
    "log_dir = './logs'\n",
    "train_csv = './labels/train_metadata_positive.csv '\n",
    "val_csv = './labels/val_metadata_positive.csv'\n",
    "num_classes = 14\n",
    "# Dataset mode would be nice to alternate through positive and non positive metadata\n",
    "\n",
    "def train_model_1(model, model_name, optimizer, lr, batch_size, image_size, num_epochs, resume=False, weighted_loss=False):\n",
    "\n",
    "    # Writer to write logs for the model\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir, model_name))\n",
    "    #writer.add_text('log', str(args), 0)\n",
    "\n",
    "    # Get the optimizer\n",
    "    params = model.parameters()\n",
    "    optimizer = get_optimizer(params, optimizer, lr) #momentum, weight_decay are optionals to be added if necessary\n",
    "\n",
    "    # Get the data loaders\n",
    "    dataloaders, dataset_sizes, class_names = make_data_loaders(train_csv,val_csv,image_dir,batch_size,image_size)\n",
    "\n",
    "    # Variables in order to store the state of training\n",
    "    best_auc_ave = 0.0  # to check if best validation accuracy\n",
    "    epoch_inti = 1  # epoch starts from here\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_auc = []\n",
    "    iter_num = 0\n",
    "\n",
    "    # Prepare to save the model\n",
    "    if not os.path.exists(model_save_dir):\n",
    "        os.makedirs(model_save_dir)\n",
    "    \n",
    "    checkpoint_file = os.path.join(model_save_dir, str(model_name + '_' + \"checkpoint.pth\"))\n",
    "    bestmodel_file = os.path.join(model_save_dir, str(model_name + '_' + \"best_model.pth\"))\n",
    "\n",
    "    ''' Check for existing training results. If it existst, and the configuration\n",
    "    is set to resume `resume==True`, resume from previous training. \n",
    "    If not, delete existing checkpoint.'''\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        if resume:\n",
    "            model, optimizer, epoch_inti, best_auc_ave = LoadModel(checkpoint_file, model, optimizer, epoch_inti,\n",
    "                                                                   best_auc_ave)\n",
    "            print(\"Checkpoint found! Resuming\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    print(model)\n",
    "    since = time.time()\n",
    "\n",
    "    for epoch in range(epoch_inti, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        print(f'Starting epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train','val']:\n",
    "            # Only Validation in every 5 cycles\n",
    "            if (phase == 'val') :\n",
    "                model.train(False)\n",
    "            elif phase == 'train':\n",
    "                model.train(True)  # Set model to training mode\n",
    "\n",
    "\n",
    "            running_loss = 0.0\n",
    "            output_list = []\n",
    "            label_list = []\n",
    "            loss_list = []\n",
    "\n",
    "            # Iterate over data.\n",
    "            for idx, data in enumerate(tqdm(dataloaders[phase])):\n",
    "\n",
    "\n",
    "                if iter_num > 100 and phase == 'train':\n",
    "                    break\n",
    "                images = data['image']\n",
    "                labels = data['labels']\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                mask = 1 * (labels >= 0)\n",
    "                mask = mask.to(device)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    torch.set_grad_enabled(True)\n",
    "                else:\n",
    "                    torch.set_grad_enabled(False)\n",
    "\n",
    "                # calculate weight for loss\n",
    "                P = 0\n",
    "                N = 0\n",
    "                for label in labels:\n",
    "                    for v in label:\n",
    "                        if int(v) == 1:\n",
    "                            P += 1\n",
    "                        else:\n",
    "                            N += 1\n",
    "                if P != 0 and N != 0:\n",
    "                    BP = (P + N) / P\n",
    "                    BN = (P + N) / N\n",
    "                    weights = torch.tensor([BP, BN], dtype=torch.float).to(device)\n",
    "                else:\n",
    "                    weights = None\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # Predicting output\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = weighted_BCELoss(outputs, labels, weights=weights)\n",
    "                \n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    iter_num += 1\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                loss_list.append(loss.item())\n",
    "                outputs = outputs.detach().to('cpu').numpy()\n",
    "                labels = labels.detach().to('cpu').numpy()\n",
    "\n",
    "                for i in range(outputs.shape[0]):\n",
    "                    output_list.append(np.where(labels[i] >= 0, outputs[i], 0).tolist())\n",
    "                    label_list.append(np.where(labels[i] >= 0, labels[i], 0).tolist())\n",
    "\n",
    "                # Saving logs\n",
    "                if idx % 100 == 0 and idx != 0:\n",
    "                    if phase == 'train':\n",
    "                        writer.add_scalar('loss/train_batch', loss.item() / outputs.shape[0], iter_num)\n",
    "                        try:\n",
    "                            auc = roc_auc_score(np.array(label_list[-100 * batch_size:]),\n",
    "                                                np.array(output_list[-100 * batch_size:]))\n",
    "                            writer.add_scalar('auc/train_batch', auc, iter_num)\n",
    "                            print('\\nAUC/Train', auc)\n",
    "                            print('Batch Loss', sum(loss_list) / len(loss_list))\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # Computing AUC\n",
    "            try:\n",
    "                epoch_auc_ave = roc_auc_score(np.array(label_list), np.array(output_list))\n",
    "                epoch_auc = roc_auc_score(np.array(label_list), np.array(output_list), average=None)\n",
    "            except ValueError:\n",
    "                epoch_auc_ave = roc_auc_score(np.array(label_list)[:, :12], np.array(output_list)[:, :12]) * (12 / 13) + \\\n",
    "                                roc_auc_score(np.array(label_list)[:, 13], np.array(output_list)[:, 13]) * (1 / 13)\n",
    "                epoch_auc = roc_auc_score(np.array(label_list)[:, :12], np.array(output_list)[:, :12], average=None)\n",
    "                epoch_auc = np.append(epoch_auc, 0)\n",
    "                epoch_auc = np.append(epoch_auc, roc_auc_score(np.array(label_list)[:, 13], np.array(output_list)[:, 13], average=None))\n",
    "\n",
    "            except:\n",
    "                epoch_auc_ave = 0\n",
    "                epoch_auc = [0 for _ in range(len(class_names))]\n",
    "\n",
    "            if phase == 'val':\n",
    "                writer.add_scalar('loss/validation', epoch_loss, epoch)\n",
    "                writer.add_scalar('auc/validation', epoch_auc_ave, epoch)\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('loss/train', epoch_loss, epoch)\n",
    "                writer.add_scalar('auc/train', epoch_auc_ave, epoch)\n",
    "\n",
    "            log_str = ''\n",
    "            log_str += 'Loss: {:.4f} AUC: {:.4f}  \\n\\n'.format(\n",
    "                epoch_loss, epoch_auc_ave)\n",
    "\n",
    "            for i, c in enumerate(class_names):\n",
    "                log_str += '{}: {:.4f}  \\n'.format(c, epoch_auc[i])\n",
    "\n",
    "            log_str += '\\n'\n",
    "            if phase == 'val':\n",
    "                print(\"\\n\\nValidation Phase \")\n",
    "            else:\n",
    "                print(\"\\n\\nTraining Phase \")\n",
    "\n",
    "            print(log_str)\n",
    "            writer.add_text('log', log_str, iter_num)\n",
    "            print(\"Best validation average AUC :\", best_auc_ave)\n",
    "            print(\"Average AUC of current epoch :\", epoch_auc_ave)\n",
    "\n",
    "            # save model with best validation AUC\n",
    "            if phase == 'val' and epoch_auc_ave > best_auc_ave:\n",
    "                best_auc = epoch_auc\n",
    "                print(\"Rewriting model with AUROC :\", round(best_auc_ave, 4), \" by model with AUROC : \",\n",
    "                      round(epoch_auc_ave, 4))\n",
    "                best_auc_ave = epoch_auc_ave\n",
    "                print('Model saved to %s' % bestmodel_file)\n",
    "                print(\"Saving the best checkpoint\")\n",
    "                SaveModel(epoch, model, optimizer, best_auc_ave, bestmodel_file)\n",
    "\n",
    "            if phase == 'train' and epoch % 1 == 0:\n",
    "                SaveModel(epoch, model, optimizer, best_auc_ave, checkpoint_file)\n",
    "\n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val AUC: {:4f}'.format(best_auc_ave))\n",
    "    print()\n",
    "    try:\n",
    "        for i, c in enumerate(class_names):\n",
    "            print('{}: {:.4f} '.format(c, best_auc[i]))\n",
    "    except:\n",
    "        for i, c in enumerate(class_names):\n",
    "            print('{}: {:.4f} '.format(c, epoch_auc[i]))\n",
    "\n",
    "\n",
    "    # load best model weights to return\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms use\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPUs!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     model \u001b[38;5;241m=\u001b[39m DataParallel(model)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m train_model(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet_18\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSGD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\nn\\modules\\module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\nn\\modules\\module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1155\u001b[0m             device,\n\u001b[0;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m             non_blocking,\n\u001b[0;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1159\u001b[0m         )\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.nn import DataParallel\n",
    "from torchvision.models import ResNet18_Weights, ResNet50_Weights, DenseNet121_Weights\n",
    "\n",
    "resnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, 14 - 1)\n",
    "\n",
    "model = resnet18\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = DataParallel(model)\n",
    "model.to(device)\n",
    "train_model1(model, \"resnet_18\", \"SGD\", 1e-4, 16, 224, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())  # Keep track of best model weights\n",
    "    best_val_loss = float('inf')  # Initialize best validation loss as infinity\n",
    "    epochs_without_improvement = 0  # Counter for epochs without improvement\n",
    "    \n",
    "    # Define the learning rate scheduler (reduce LR on plateau)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        print(f'Starting epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        # Training loop\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['labels'].to(device).float()\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 100 == 99:  # Print every 10 batches\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        # Validation at the end of each epoch\n",
    "        val_loss = validate_model(model, val_loader, criterion)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {running_loss / len(train_loader):.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss  # Update best validation loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())  # Save the best model weights\n",
    "            epochs_without_improvement = 0  # Reset counter\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f'No improvement in validation loss for {epochs_without_improvement} epoch(s).')\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f'Early stopping after {epochs_without_improvement} epochs without improvement.')\n",
    "            break\n",
    "\n",
    "        # Update the learning rate based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    # Load best model weights before returning\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print('Training complete. Best Validation Loss:', best_val_loss)\n",
    "    return model\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['labels'].to(device).float()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(val_loader)  # Return average validation loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test function\n",
    "\n",
    "Test function that generates the testing values that are necessary for the evaluation of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    threshold = 0.5  # Threshold for multi-label classification\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            predicted = (torch.sigmoid(outputs) > threshold).float()\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Paths\n",
    "train_csv = './labels/train_metadata.csv '\n",
    "train_image_dir = './resized_images'\n",
    "val_csv = './labels/val_metadata.csv'\n",
    "val_image_dir = './resized_images'\n",
    "train_p_csv = './labels/train_metadata_positive.csv '\n",
    "val_p_csv = './labels/val_metadata_positive.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import os\n",
    "\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "    ])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "    ])\n",
    "\n",
    "train_dataset = ChestXRay(df_dir=train_csv, image_dir=train_image_dir, transform=train_transforms)\n",
    "val_dataset = ChestXRay(df_dir=val_csv, image_dir=val_image_dir, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset_p = ChestXRay(df_dir=train_p_csv, image_dir=train_image_dir, transform=train_transforms)\n",
    "val_dataset_p = ChestXRay(df_dir=val_p_csv, image_dir=val_image_dir, transform=val_transforms)\n",
    "\n",
    "train_loader_p = DataLoader(train_dataset_p, batch_size=batch_size, shuffle=True)\n",
    "val_loader_p = DataLoader(val_dataset_p, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet18_Weights, ResNet50_Weights, DenseNet121_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/10\n",
      "Epoch [1/10], Step [100/2272], Loss: 0.3250\n",
      "Epoch [1/10], Step [200/2272], Loss: 0.3081\n",
      "Epoch [1/10], Step [300/2272], Loss: 0.3047\n",
      "Epoch [1/10], Step [400/2272], Loss: 0.3101\n",
      "Epoch [1/10], Step [500/2272], Loss: 0.3028\n",
      "Epoch [1/10], Step [600/2272], Loss: 0.3017\n",
      "Epoch [1/10], Step [700/2272], Loss: 0.3002\n",
      "Epoch [1/10], Step [800/2272], Loss: 0.3017\n",
      "Epoch [1/10], Step [900/2272], Loss: 0.3037\n",
      "Epoch [1/10], Step [1000/2272], Loss: 0.3039\n",
      "Epoch [1/10], Step [1100/2272], Loss: 0.3019\n",
      "Epoch [1/10], Step [1200/2272], Loss: 0.3007\n",
      "Epoch [1/10], Step [1300/2272], Loss: 0.3042\n",
      "Epoch [1/10], Step [1400/2272], Loss: 0.2951\n",
      "Epoch [1/10], Step [1500/2272], Loss: 0.2948\n",
      "Epoch [1/10], Step [1600/2272], Loss: 0.3024\n",
      "Epoch [1/10], Step [1700/2272], Loss: 0.2973\n",
      "Epoch [1/10], Step [1800/2272], Loss: 0.2970\n",
      "Epoch [1/10], Step [1900/2272], Loss: 0.3003\n",
      "Epoch [1/10], Step [2000/2272], Loss: 0.2975\n",
      "Epoch [1/10], Step [2100/2272], Loss: 0.2998\n",
      "Epoch [1/10], Step [2200/2272], Loss: 0.2946\n",
      "Epoch [1/10], Training Loss: 0.0093, Validation Loss: 0.3012\n",
      "Starting epoch 2/10\n",
      "Epoch [2/10], Step [100/2272], Loss: 0.2980\n",
      "Epoch [2/10], Step [200/2272], Loss: 0.2909\n",
      "Epoch [2/10], Step [300/2272], Loss: 0.2976\n",
      "Epoch [2/10], Step [400/2272], Loss: 0.3002\n",
      "Epoch [2/10], Step [500/2272], Loss: 0.2990\n",
      "Epoch [2/10], Step [600/2272], Loss: 0.2969\n",
      "Epoch [2/10], Step [700/2272], Loss: 0.2952\n",
      "Epoch [2/10], Step [800/2272], Loss: 0.3050\n",
      "Epoch [2/10], Step [900/2272], Loss: 0.2915\n",
      "Epoch [2/10], Step [1000/2272], Loss: 0.2921\n",
      "Epoch [2/10], Step [1100/2272], Loss: 0.2977\n",
      "Epoch [2/10], Step [1200/2272], Loss: 0.2918\n",
      "Epoch [2/10], Step [1300/2272], Loss: 0.2918\n",
      "Epoch [2/10], Step [1400/2272], Loss: 0.2945\n",
      "Epoch [2/10], Step [1500/2272], Loss: 0.2936\n",
      "Epoch [2/10], Step [1600/2272], Loss: 0.2913\n",
      "Epoch [2/10], Step [1700/2272], Loss: 0.2963\n",
      "Epoch [2/10], Step [1800/2272], Loss: 0.2946\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(resnet18\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet18\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     24\u001b[0m     images \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     25\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[5], line 59\u001b[0m, in \u001b[0;36mChestXRay.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# Get image path\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     img_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages\u001b[38;5;241m.\u001b[39miloc[idx])\n\u001b[1;32m---> 59\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# Get labels\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx])\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\PIL\\Image.py:995\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    993\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m--> 995\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    997\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\PIL\\ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, len(train_dataset_p.data_frame.columns) - 1)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(resnet18.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(resnet18, train_loader_p, val_loader_p, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Test the model\n",
    "#test_model(resnet18, val_loader_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved at ./model_checkpoint_resnet18_v1_10ep_p.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = \"./model_checkpoint_resnet18_v1_10ep_p.pth\"\n",
    "\n",
    "store_model(resnet18, optimizer, num_epochs + 1, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/10\n",
      "Epoch [1/10], Step [100/2272], Loss: 0.3198\n",
      "Epoch [1/10], Step [200/2272], Loss: 0.2995\n",
      "Epoch [1/10], Step [300/2272], Loss: 0.2932\n",
      "Epoch [1/10], Step [400/2272], Loss: 0.2928\n",
      "Epoch [1/10], Step [500/2272], Loss: 0.3001\n",
      "Epoch [1/10], Step [600/2272], Loss: 0.2937\n",
      "Epoch [1/10], Step [700/2272], Loss: 0.2936\n",
      "Epoch [1/10], Step [800/2272], Loss: 0.2869\n",
      "Epoch [1/10], Step [900/2272], Loss: 0.2833\n",
      "Epoch [1/10], Step [1000/2272], Loss: 0.2815\n",
      "Epoch [1/10], Step [1100/2272], Loss: 0.2860\n",
      "Epoch [1/10], Step [1200/2272], Loss: 0.2854\n",
      "Epoch [1/10], Step [1300/2272], Loss: 0.2805\n",
      "Epoch [1/10], Step [1400/2272], Loss: 0.2832\n",
      "Epoch [1/10], Step [1500/2272], Loss: 0.2819\n",
      "Epoch [1/10], Step [1600/2272], Loss: 0.2763\n",
      "Epoch [1/10], Step [1700/2272], Loss: 0.2836\n",
      "Epoch [1/10], Step [1800/2272], Loss: 0.2824\n",
      "Epoch [1/10], Step [1900/2272], Loss: 0.2768\n",
      "Epoch [1/10], Step [2000/2272], Loss: 0.2827\n",
      "Epoch [1/10], Step [2100/2272], Loss: 0.2790\n",
      "Epoch [1/10], Step [2200/2272], Loss: 0.2798\n",
      "Epoch [1/10], Training Loss: 0.0088, Validation Loss: 0.2843\n",
      "Starting epoch 2/10\n",
      "Epoch [2/10], Step [100/2272], Loss: 0.2766\n",
      "Epoch [2/10], Step [200/2272], Loss: 0.2742\n",
      "Epoch [2/10], Step [300/2272], Loss: 0.2740\n",
      "Epoch [2/10], Step [400/2272], Loss: 0.2726\n",
      "Epoch [2/10], Step [500/2272], Loss: 0.2746\n",
      "Epoch [2/10], Step [600/2272], Loss: 0.2750\n",
      "Epoch [2/10], Step [700/2272], Loss: 0.2614\n",
      "Epoch [2/10], Step [800/2272], Loss: 0.2684\n",
      "Epoch [2/10], Step [900/2272], Loss: 0.2778\n",
      "Epoch [2/10], Step [1000/2272], Loss: 0.2715\n",
      "Epoch [2/10], Step [1100/2272], Loss: 0.2684\n",
      "Epoch [2/10], Step [1200/2272], Loss: 0.2724\n",
      "Epoch [2/10], Step [1300/2272], Loss: 0.2735\n",
      "Epoch [2/10], Step [1400/2272], Loss: 0.2736\n",
      "Epoch [2/10], Step [1500/2272], Loss: 0.2696\n",
      "Epoch [2/10], Step [1600/2272], Loss: 0.2691\n",
      "Epoch [2/10], Step [1700/2272], Loss: 0.2742\n",
      "Epoch [2/10], Step [1800/2272], Loss: 0.2656\n",
      "Epoch [2/10], Step [1900/2272], Loss: 0.2704\n",
      "Epoch [2/10], Step [2000/2272], Loss: 0.2750\n",
      "Epoch [2/10], Step [2100/2272], Loss: 0.2655\n",
      "Epoch [2/10], Step [2200/2272], Loss: 0.2707\n",
      "Epoch [2/10], Training Loss: 0.0086, Validation Loss: 0.2753\n",
      "Starting epoch 3/10\n",
      "Epoch [3/10], Step [100/2272], Loss: 0.2738\n",
      "Epoch [3/10], Step [200/2272], Loss: 0.2604\n",
      "Epoch [3/10], Step [300/2272], Loss: 0.2672\n",
      "Epoch [3/10], Step [400/2272], Loss: 0.2646\n",
      "Epoch [3/10], Step [500/2272], Loss: 0.2632\n",
      "Epoch [3/10], Step [600/2272], Loss: 0.2601\n",
      "Epoch [3/10], Step [700/2272], Loss: 0.2686\n",
      "Epoch [3/10], Step [800/2272], Loss: 0.2680\n",
      "Epoch [3/10], Step [900/2272], Loss: 0.2660\n",
      "Epoch [3/10], Step [1000/2272], Loss: 0.2625\n",
      "Epoch [3/10], Step [1100/2272], Loss: 0.2645\n",
      "Epoch [3/10], Step [1200/2272], Loss: 0.2663\n",
      "Epoch [3/10], Step [1300/2272], Loss: 0.2637\n",
      "Epoch [3/10], Step [1400/2272], Loss: 0.2599\n",
      "Epoch [3/10], Step [1500/2272], Loss: 0.2635\n",
      "Epoch [3/10], Step [1600/2272], Loss: 0.2654\n",
      "Epoch [3/10], Step [1700/2272], Loss: 0.2614\n",
      "Epoch [3/10], Step [1800/2272], Loss: 0.2662\n",
      "Epoch [3/10], Step [1900/2272], Loss: 0.2636\n",
      "Epoch [3/10], Step [2000/2272], Loss: 0.2589\n",
      "Epoch [3/10], Step [2100/2272], Loss: 0.2607\n",
      "Epoch [3/10], Step [2200/2272], Loss: 0.2628\n",
      "Epoch [3/10], Training Loss: 0.0084, Validation Loss: 0.2726\n",
      "Starting epoch 4/10\n",
      "Epoch [4/10], Step [100/2272], Loss: 0.2569\n",
      "Epoch [4/10], Step [200/2272], Loss: 0.2586\n",
      "Epoch [4/10], Step [300/2272], Loss: 0.2554\n",
      "Epoch [4/10], Step [400/2272], Loss: 0.2611\n",
      "Epoch [4/10], Step [500/2272], Loss: 0.2584\n",
      "Epoch [4/10], Step [600/2272], Loss: 0.2598\n",
      "Epoch [4/10], Step [700/2272], Loss: 0.2606\n",
      "Epoch [4/10], Step [800/2272], Loss: 0.2582\n",
      "Epoch [4/10], Step [900/2272], Loss: 0.2522\n",
      "Epoch [4/10], Step [1000/2272], Loss: 0.2565\n",
      "Epoch [4/10], Step [1100/2272], Loss: 0.2624\n",
      "Epoch [4/10], Step [1200/2272], Loss: 0.2618\n",
      "Epoch [4/10], Step [1300/2272], Loss: 0.2601\n",
      "Epoch [4/10], Step [1400/2272], Loss: 0.2556\n",
      "Epoch [4/10], Step [1500/2272], Loss: 0.2573\n",
      "Epoch [4/10], Step [1600/2272], Loss: 0.2624\n",
      "Epoch [4/10], Step [1700/2272], Loss: 0.2616\n",
      "Epoch [4/10], Step [1800/2272], Loss: 0.2577\n",
      "Epoch [4/10], Step [1900/2272], Loss: 0.2619\n",
      "Epoch [4/10], Step [2000/2272], Loss: 0.2584\n",
      "Epoch [4/10], Step [2100/2272], Loss: 0.2545\n",
      "Epoch [4/10], Step [2200/2272], Loss: 0.2561\n",
      "Epoch [4/10], Training Loss: 0.0080, Validation Loss: 0.2663\n",
      "Starting epoch 5/10\n",
      "Epoch [5/10], Step [100/2272], Loss: 0.2545\n",
      "Epoch [5/10], Step [200/2272], Loss: 0.2502\n",
      "Epoch [5/10], Step [300/2272], Loss: 0.2569\n",
      "Epoch [5/10], Step [400/2272], Loss: 0.2521\n",
      "Epoch [5/10], Step [500/2272], Loss: 0.2545\n",
      "Epoch [5/10], Step [600/2272], Loss: 0.2560\n",
      "Epoch [5/10], Step [700/2272], Loss: 0.2494\n",
      "Epoch [5/10], Step [800/2272], Loss: 0.2548\n",
      "Epoch [5/10], Step [900/2272], Loss: 0.2529\n",
      "Epoch [5/10], Step [1000/2272], Loss: 0.2565\n",
      "Epoch [5/10], Step [1100/2272], Loss: 0.2512\n",
      "Epoch [5/10], Step [1200/2272], Loss: 0.2522\n",
      "Epoch [5/10], Step [1300/2272], Loss: 0.2579\n",
      "Epoch [5/10], Step [1400/2272], Loss: 0.2528\n",
      "Epoch [5/10], Step [1500/2272], Loss: 0.2516\n",
      "Epoch [5/10], Step [1600/2272], Loss: 0.2523\n",
      "Epoch [5/10], Step [1700/2272], Loss: 0.2488\n",
      "Epoch [5/10], Step [1800/2272], Loss: 0.2552\n",
      "Epoch [5/10], Step [1900/2272], Loss: 0.2503\n",
      "Epoch [5/10], Step [2000/2272], Loss: 0.2553\n",
      "Epoch [5/10], Step [2100/2272], Loss: 0.2549\n",
      "Epoch [5/10], Step [2200/2272], Loss: 0.2560\n",
      "Epoch [5/10], Training Loss: 0.0081, Validation Loss: 0.2664\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 6/10\n",
      "Epoch [6/10], Step [100/2272], Loss: 0.2455\n",
      "Epoch [6/10], Step [200/2272], Loss: 0.2415\n",
      "Epoch [6/10], Step [300/2272], Loss: 0.2459\n",
      "Epoch [6/10], Step [400/2272], Loss: 0.2500\n",
      "Epoch [6/10], Step [500/2272], Loss: 0.2453\n",
      "Epoch [6/10], Step [600/2272], Loss: 0.2541\n",
      "Epoch [6/10], Step [700/2272], Loss: 0.2527\n",
      "Epoch [6/10], Step [800/2272], Loss: 0.2448\n",
      "Epoch [6/10], Step [900/2272], Loss: 0.2510\n",
      "Epoch [6/10], Step [1000/2272], Loss: 0.2477\n",
      "Epoch [6/10], Step [1100/2272], Loss: 0.2480\n",
      "Epoch [6/10], Step [1200/2272], Loss: 0.2495\n",
      "Epoch [6/10], Step [1300/2272], Loss: 0.2508\n",
      "Epoch [6/10], Step [1400/2272], Loss: 0.2536\n",
      "Epoch [6/10], Step [1500/2272], Loss: 0.2499\n",
      "Epoch [6/10], Step [1600/2272], Loss: 0.2419\n",
      "Epoch [6/10], Step [1700/2272], Loss: 0.2455\n",
      "Epoch [6/10], Step [1800/2272], Loss: 0.2486\n",
      "Epoch [6/10], Step [1900/2272], Loss: 0.2453\n",
      "Epoch [6/10], Step [2000/2272], Loss: 0.2511\n",
      "Epoch [6/10], Step [2100/2272], Loss: 0.2499\n",
      "Epoch [6/10], Step [2200/2272], Loss: 0.2549\n",
      "Epoch [6/10], Training Loss: 0.0079, Validation Loss: 0.2774\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Starting epoch 7/10\n",
      "Epoch [7/10], Step [100/2272], Loss: 0.2411\n",
      "Epoch [7/10], Step [200/2272], Loss: 0.2397\n",
      "Epoch [7/10], Step [300/2272], Loss: 0.2327\n",
      "Epoch [7/10], Step [400/2272], Loss: 0.2407\n",
      "Epoch [7/10], Step [500/2272], Loss: 0.2427\n",
      "Epoch [7/10], Step [600/2272], Loss: 0.2410\n",
      "Epoch [7/10], Step [700/2272], Loss: 0.2452\n",
      "Epoch [7/10], Step [800/2272], Loss: 0.2468\n",
      "Epoch [7/10], Step [900/2272], Loss: 0.2429\n",
      "Epoch [7/10], Step [1000/2272], Loss: 0.2430\n",
      "Epoch [7/10], Step [1100/2272], Loss: 0.2443\n",
      "Epoch [7/10], Step [1200/2272], Loss: 0.2429\n",
      "Epoch [7/10], Step [1300/2272], Loss: 0.2447\n",
      "Epoch [7/10], Step [1400/2272], Loss: 0.2396\n",
      "Epoch [7/10], Step [1500/2272], Loss: 0.2364\n",
      "Epoch [7/10], Step [1600/2272], Loss: 0.2487\n",
      "Epoch [7/10], Step [1700/2272], Loss: 0.2408\n",
      "Epoch [7/10], Step [1800/2272], Loss: 0.2499\n",
      "Epoch [7/10], Step [1900/2272], Loss: 0.2498\n",
      "Epoch [7/10], Step [2000/2272], Loss: 0.2465\n",
      "Epoch [7/10], Step [2100/2272], Loss: 0.2451\n",
      "Epoch [7/10], Step [2200/2272], Loss: 0.2408\n",
      "Epoch [7/10], Training Loss: 0.0077, Validation Loss: 0.2671\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Starting epoch 8/10\n",
      "Epoch [8/10], Step [100/2272], Loss: 0.2247\n",
      "Epoch [8/10], Step [200/2272], Loss: 0.2372\n",
      "Epoch [8/10], Step [300/2272], Loss: 0.2352\n",
      "Epoch [8/10], Step [400/2272], Loss: 0.2345\n",
      "Epoch [8/10], Step [500/2272], Loss: 0.2399\n",
      "Epoch [8/10], Step [600/2272], Loss: 0.2359\n",
      "Epoch [8/10], Step [700/2272], Loss: 0.2352\n",
      "Epoch [8/10], Step [800/2272], Loss: 0.2346\n",
      "Epoch [8/10], Step [900/2272], Loss: 0.2324\n",
      "Epoch [8/10], Step [1000/2272], Loss: 0.2386\n",
      "Epoch [8/10], Step [1100/2272], Loss: 0.2421\n",
      "Epoch [8/10], Step [1200/2272], Loss: 0.2343\n",
      "Epoch [8/10], Step [1300/2272], Loss: 0.2346\n",
      "Epoch [8/10], Step [1400/2272], Loss: 0.2380\n",
      "Epoch [8/10], Step [1500/2272], Loss: 0.2338\n",
      "Epoch [8/10], Step [1600/2272], Loss: 0.2419\n",
      "Epoch [8/10], Step [1700/2272], Loss: 0.2413\n",
      "Epoch [8/10], Step [1800/2272], Loss: 0.2391\n",
      "Epoch [8/10], Step [1900/2272], Loss: 0.2337\n",
      "Epoch [8/10], Step [2000/2272], Loss: 0.2409\n",
      "Epoch [8/10], Step [2100/2272], Loss: 0.2346\n",
      "Epoch [8/10], Step [2200/2272], Loss: 0.2441\n",
      "Epoch [8/10], Training Loss: 0.0076, Validation Loss: 0.2651\n",
      "Starting epoch 9/10\n",
      "Epoch [9/10], Step [100/2272], Loss: 0.2219\n",
      "Epoch [9/10], Step [200/2272], Loss: 0.2289\n",
      "Epoch [9/10], Step [300/2272], Loss: 0.2334\n",
      "Epoch [9/10], Step [400/2272], Loss: 0.2244\n",
      "Epoch [9/10], Step [500/2272], Loss: 0.2306\n",
      "Epoch [9/10], Step [600/2272], Loss: 0.2243\n",
      "Epoch [9/10], Step [700/2272], Loss: 0.2308\n",
      "Epoch [9/10], Step [800/2272], Loss: 0.2287\n",
      "Epoch [9/10], Step [900/2272], Loss: 0.2309\n",
      "Epoch [9/10], Step [1000/2272], Loss: 0.2282\n",
      "Epoch [9/10], Step [1100/2272], Loss: 0.2315\n",
      "Epoch [9/10], Step [1200/2272], Loss: 0.2320\n",
      "Epoch [9/10], Step [1300/2272], Loss: 0.2321\n",
      "Epoch [9/10], Step [1400/2272], Loss: 0.2304\n",
      "Epoch [9/10], Step [1500/2272], Loss: 0.2272\n",
      "Epoch [9/10], Step [1600/2272], Loss: 0.2289\n",
      "Epoch [9/10], Step [1700/2272], Loss: 0.2367\n",
      "Epoch [9/10], Step [1800/2272], Loss: 0.2312\n",
      "Epoch [9/10], Step [1900/2272], Loss: 0.2242\n",
      "Epoch [9/10], Step [2000/2272], Loss: 0.2357\n",
      "Epoch [9/10], Step [2100/2272], Loss: 0.2284\n",
      "Epoch [9/10], Step [2200/2272], Loss: 0.2317\n",
      "Epoch [9/10], Training Loss: 0.0072, Validation Loss: 0.2690\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 10/10\n",
      "Epoch [10/10], Step [100/2272], Loss: 0.2143\n",
      "Epoch [10/10], Step [200/2272], Loss: 0.2203\n",
      "Epoch [10/10], Step [300/2272], Loss: 0.2188\n",
      "Epoch [10/10], Step [400/2272], Loss: 0.2166\n",
      "Epoch [10/10], Step [500/2272], Loss: 0.2191\n",
      "Epoch [10/10], Step [600/2272], Loss: 0.2205\n",
      "Epoch [10/10], Step [700/2272], Loss: 0.2262\n",
      "Epoch [10/10], Step [800/2272], Loss: 0.2213\n",
      "Epoch [10/10], Step [900/2272], Loss: 0.2174\n",
      "Epoch [10/10], Step [1000/2272], Loss: 0.2161\n",
      "Epoch [10/10], Step [1100/2272], Loss: 0.2194\n",
      "Epoch [10/10], Step [1200/2272], Loss: 0.2184\n",
      "Epoch [10/10], Step [1300/2272], Loss: 0.2194\n",
      "Epoch [10/10], Step [1400/2272], Loss: 0.2211\n",
      "Epoch [10/10], Step [1500/2272], Loss: 0.2189\n",
      "Epoch [10/10], Step [1600/2272], Loss: 0.2229\n",
      "Epoch [10/10], Step [1700/2272], Loss: 0.2249\n",
      "Epoch [10/10], Step [1800/2272], Loss: 0.2183\n",
      "Epoch [10/10], Step [1900/2272], Loss: 0.2264\n",
      "Epoch [10/10], Step [2000/2272], Loss: 0.2225\n",
      "Epoch [10/10], Step [2100/2272], Loss: 0.2249\n",
      "Epoch [10/10], Step [2200/2272], Loss: 0.2247\n",
      "Epoch [10/10], Training Loss: 0.0071, Validation Loss: 0.2701\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Training complete. Best Validation Loss: 0.26505569531582296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50 = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_ftrs, len(train_dataset_p.data_frame.columns) - 1)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(resnet50.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(resnet50, train_loader_p, val_loader_p, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Test the model\n",
    "#test_model(resnet50, val_loader_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved at ./model_checkpoint_resnet50_v1_10ep_p.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = \"./model_checkpoint_resnet50_v1_10ep_p.pth\"\n",
    "\n",
    "store_model(resnet50, optimizer, num_epochs + 1, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/10\n",
      "Epoch [1/10], Step [100/2272], Loss: 0.3198\n",
      "Epoch [1/10], Step [200/2272], Loss: 0.3023\n",
      "Epoch [1/10], Step [300/2272], Loss: 0.2998\n",
      "Epoch [1/10], Step [400/2272], Loss: 0.3036\n",
      "Epoch [1/10], Step [500/2272], Loss: 0.2958\n",
      "Epoch [1/10], Step [600/2272], Loss: 0.2985\n",
      "Epoch [1/10], Step [700/2272], Loss: 0.3031\n",
      "Epoch [1/10], Step [800/2272], Loss: 0.3031\n",
      "Epoch [1/10], Step [900/2272], Loss: 0.3045\n",
      "Epoch [1/10], Step [1000/2272], Loss: 0.2978\n",
      "Epoch [1/10], Step [1100/2272], Loss: 0.2988\n",
      "Epoch [1/10], Step [1200/2272], Loss: 0.3044\n",
      "Epoch [1/10], Step [1300/2272], Loss: 0.3014\n",
      "Epoch [1/10], Step [1400/2272], Loss: 0.3008\n",
      "Epoch [1/10], Step [1500/2272], Loss: 0.2976\n",
      "Epoch [1/10], Step [1600/2272], Loss: 0.2981\n",
      "Epoch [1/10], Step [1700/2272], Loss: 0.2963\n",
      "Epoch [1/10], Step [1800/2272], Loss: 0.3024\n",
      "Epoch [1/10], Step [1900/2272], Loss: 0.2932\n",
      "Epoch [1/10], Step [2000/2272], Loss: 0.2955\n",
      "Epoch [1/10], Step [2100/2272], Loss: 0.2958\n",
      "Epoch [1/10], Step [2200/2272], Loss: 0.2895\n",
      "Epoch [1/10], Training Loss: 0.0091, Validation Loss: 0.2994\n",
      "Starting epoch 2/10\n",
      "Epoch [2/10], Step [100/2272], Loss: 0.2939\n",
      "Epoch [2/10], Step [200/2272], Loss: 0.2917\n",
      "Epoch [2/10], Step [300/2272], Loss: 0.2912\n",
      "Epoch [2/10], Step [400/2272], Loss: 0.2917\n",
      "Epoch [2/10], Step [500/2272], Loss: 0.2903\n",
      "Epoch [2/10], Step [600/2272], Loss: 0.2885\n",
      "Epoch [2/10], Step [700/2272], Loss: 0.2840\n",
      "Epoch [2/10], Step [800/2272], Loss: 0.2914\n",
      "Epoch [2/10], Step [900/2272], Loss: 0.2935\n",
      "Epoch [2/10], Step [1000/2272], Loss: 0.2961\n",
      "Epoch [2/10], Step [1100/2272], Loss: 0.2913\n",
      "Epoch [2/10], Step [1200/2272], Loss: 0.2864\n",
      "Epoch [2/10], Step [1300/2272], Loss: 0.2856\n",
      "Epoch [2/10], Step [1400/2272], Loss: 0.2835\n",
      "Epoch [2/10], Step [1500/2272], Loss: 0.2823\n",
      "Epoch [2/10], Step [1600/2272], Loss: 0.2915\n",
      "Epoch [2/10], Step [1700/2272], Loss: 0.2904\n",
      "Epoch [2/10], Step [1800/2272], Loss: 0.2776\n",
      "Epoch [2/10], Step [1900/2272], Loss: 0.2823\n",
      "Epoch [2/10], Step [2000/2272], Loss: 0.2763\n",
      "Epoch [2/10], Step [2100/2272], Loss: 0.2763\n",
      "Epoch [2/10], Step [2200/2272], Loss: 0.2779\n",
      "Epoch [2/10], Training Loss: 0.0087, Validation Loss: 0.2839\n",
      "Starting epoch 3/10\n",
      "Epoch [3/10], Step [100/2272], Loss: 0.2862\n",
      "Epoch [3/10], Step [200/2272], Loss: 0.2767\n",
      "Epoch [3/10], Step [300/2272], Loss: 0.2805\n",
      "Epoch [3/10], Step [400/2272], Loss: 0.2782\n",
      "Epoch [3/10], Step [500/2272], Loss: 0.2734\n",
      "Epoch [3/10], Step [600/2272], Loss: 0.2732\n",
      "Epoch [3/10], Step [700/2272], Loss: 0.2803\n",
      "Epoch [3/10], Step [800/2272], Loss: 0.2752\n",
      "Epoch [3/10], Step [900/2272], Loss: 0.2842\n",
      "Epoch [3/10], Step [1000/2272], Loss: 0.2788\n",
      "Epoch [3/10], Step [1100/2272], Loss: 0.2786\n",
      "Epoch [3/10], Step [1200/2272], Loss: 0.2805\n",
      "Epoch [3/10], Step [1300/2272], Loss: 0.2787\n",
      "Epoch [3/10], Step [1400/2272], Loss: 0.2793\n",
      "Epoch [3/10], Step [1500/2272], Loss: 0.2757\n",
      "Epoch [3/10], Step [1600/2272], Loss: 0.2769\n",
      "Epoch [3/10], Step [1700/2272], Loss: 0.2768\n",
      "Epoch [3/10], Step [1800/2272], Loss: 0.2763\n",
      "Epoch [3/10], Step [1900/2272], Loss: 0.2758\n",
      "Epoch [3/10], Step [2000/2272], Loss: 0.2756\n",
      "Epoch [3/10], Step [2100/2272], Loss: 0.2777\n",
      "Epoch [3/10], Step [2200/2272], Loss: 0.2836\n",
      "Epoch [3/10], Training Loss: 0.0088, Validation Loss: 0.2818\n",
      "Starting epoch 4/10\n",
      "Epoch [4/10], Step [100/2272], Loss: 0.2730\n",
      "Epoch [4/10], Step [200/2272], Loss: 0.2744\n",
      "Epoch [4/10], Step [300/2272], Loss: 0.2779\n",
      "Epoch [4/10], Step [400/2272], Loss: 0.2711\n",
      "Epoch [4/10], Step [500/2272], Loss: 0.2775\n",
      "Epoch [4/10], Step [600/2272], Loss: 0.2754\n",
      "Epoch [4/10], Step [700/2272], Loss: 0.2737\n",
      "Epoch [4/10], Step [800/2272], Loss: 0.2778\n",
      "Epoch [4/10], Step [900/2272], Loss: 0.2731\n",
      "Epoch [4/10], Step [1000/2272], Loss: 0.2696\n",
      "Epoch [4/10], Step [1100/2272], Loss: 0.2743\n",
      "Epoch [4/10], Step [1200/2272], Loss: 0.2716\n",
      "Epoch [4/10], Step [1300/2272], Loss: 0.2725\n",
      "Epoch [4/10], Step [1400/2272], Loss: 0.2771\n",
      "Epoch [4/10], Step [1500/2272], Loss: 0.2708\n",
      "Epoch [4/10], Step [1600/2272], Loss: 0.2750\n",
      "Epoch [4/10], Step [1700/2272], Loss: 0.2693\n",
      "Epoch [4/10], Step [1800/2272], Loss: 0.2711\n",
      "Epoch [4/10], Step [1900/2272], Loss: 0.2646\n",
      "Epoch [4/10], Step [2000/2272], Loss: 0.2653\n",
      "Epoch [4/10], Step [2100/2272], Loss: 0.2692\n",
      "Epoch [4/10], Step [2200/2272], Loss: 0.2686\n",
      "Epoch [4/10], Training Loss: 0.0085, Validation Loss: 0.2809\n",
      "Starting epoch 5/10\n",
      "Epoch [5/10], Step [100/2272], Loss: 0.2667\n",
      "Epoch [5/10], Step [200/2272], Loss: 0.2757\n",
      "Epoch [5/10], Step [300/2272], Loss: 0.2841\n",
      "Epoch [5/10], Step [400/2272], Loss: 0.2750\n",
      "Epoch [5/10], Step [500/2272], Loss: 0.2745\n",
      "Epoch [5/10], Step [600/2272], Loss: 0.2751\n",
      "Epoch [5/10], Step [700/2272], Loss: 0.2678\n",
      "Epoch [5/10], Step [800/2272], Loss: 0.2707\n",
      "Epoch [5/10], Step [900/2272], Loss: 0.2718\n",
      "Epoch [5/10], Step [1000/2272], Loss: 0.2671\n",
      "Epoch [5/10], Step [1100/2272], Loss: 0.2743\n",
      "Epoch [5/10], Step [1200/2272], Loss: 0.2647\n",
      "Epoch [5/10], Step [1300/2272], Loss: 0.2727\n",
      "Epoch [5/10], Step [1400/2272], Loss: 0.2660\n",
      "Epoch [5/10], Step [1500/2272], Loss: 0.2651\n",
      "Epoch [5/10], Step [1600/2272], Loss: 0.2682\n",
      "Epoch [5/10], Step [1700/2272], Loss: 0.2683\n",
      "Epoch [5/10], Step [1800/2272], Loss: 0.2697\n",
      "Epoch [5/10], Step [1900/2272], Loss: 0.2678\n",
      "Epoch [5/10], Step [2000/2272], Loss: 0.2692\n",
      "Epoch [5/10], Step [2100/2272], Loss: 0.2667\n",
      "Epoch [5/10], Step [2200/2272], Loss: 0.2611\n",
      "Epoch [5/10], Training Loss: 0.0084, Validation Loss: 0.2722\n",
      "Starting epoch 6/10\n",
      "Epoch [6/10], Step [100/2272], Loss: 0.2639\n",
      "Epoch [6/10], Step [200/2272], Loss: 0.2651\n",
      "Epoch [6/10], Step [300/2272], Loss: 0.2706\n",
      "Epoch [6/10], Step [400/2272], Loss: 0.2648\n",
      "Epoch [6/10], Step [500/2272], Loss: 0.2611\n",
      "Epoch [6/10], Step [600/2272], Loss: 0.2644\n",
      "Epoch [6/10], Step [700/2272], Loss: 0.2586\n",
      "Epoch [6/10], Step [800/2272], Loss: 0.2629\n",
      "Epoch [6/10], Step [900/2272], Loss: 0.2674\n",
      "Epoch [6/10], Step [1000/2272], Loss: 0.2624\n",
      "Epoch [6/10], Step [1100/2272], Loss: 0.2681\n",
      "Epoch [6/10], Step [1200/2272], Loss: 0.2696\n",
      "Epoch [6/10], Step [1300/2272], Loss: 0.2650\n",
      "Epoch [6/10], Step [1400/2272], Loss: 0.2586\n",
      "Epoch [6/10], Step [1500/2272], Loss: 0.2687\n",
      "Epoch [6/10], Step [1600/2272], Loss: 0.2642\n",
      "Epoch [6/10], Step [1700/2272], Loss: 0.2683\n",
      "Epoch [6/10], Step [1800/2272], Loss: 0.2652\n",
      "Epoch [6/10], Step [1900/2272], Loss: 0.2614\n",
      "Epoch [6/10], Step [2000/2272], Loss: 0.2640\n",
      "Epoch [6/10], Step [2100/2272], Loss: 0.2656\n",
      "Epoch [6/10], Step [2200/2272], Loss: 0.2626\n",
      "Epoch [6/10], Training Loss: 0.0083, Validation Loss: 0.2704\n",
      "Starting epoch 7/10\n",
      "Epoch [7/10], Step [100/2272], Loss: 0.2675\n",
      "Epoch [7/10], Step [200/2272], Loss: 0.2604\n",
      "Epoch [7/10], Step [300/2272], Loss: 0.2591\n",
      "Epoch [7/10], Step [400/2272], Loss: 0.2673\n",
      "Epoch [7/10], Step [500/2272], Loss: 0.2668\n",
      "Epoch [7/10], Step [600/2272], Loss: 0.2646\n",
      "Epoch [7/10], Step [700/2272], Loss: 0.2663\n",
      "Epoch [7/10], Step [800/2272], Loss: 0.2635\n",
      "Epoch [7/10], Step [900/2272], Loss: 0.2614\n",
      "Epoch [7/10], Step [1000/2272], Loss: 0.2590\n",
      "Epoch [7/10], Step [1100/2272], Loss: 0.2619\n",
      "Epoch [7/10], Step [1200/2272], Loss: 0.2625\n",
      "Epoch [7/10], Step [1300/2272], Loss: 0.2594\n",
      "Epoch [7/10], Step [1400/2272], Loss: 0.2556\n",
      "Epoch [7/10], Step [1500/2272], Loss: 0.2547\n",
      "Epoch [7/10], Step [1600/2272], Loss: 0.2603\n",
      "Epoch [7/10], Step [1700/2272], Loss: 0.2660\n",
      "Epoch [7/10], Step [1800/2272], Loss: 0.2654\n",
      "Epoch [7/10], Step [1900/2272], Loss: 0.2599\n",
      "Epoch [7/10], Step [2000/2272], Loss: 0.2579\n",
      "Epoch [7/10], Step [2100/2272], Loss: 0.2583\n",
      "Epoch [7/10], Step [2200/2272], Loss: 0.2633\n",
      "Epoch [7/10], Training Loss: 0.0082, Validation Loss: 0.2702\n",
      "Starting epoch 8/10\n",
      "Epoch [8/10], Step [100/2272], Loss: 0.2520\n",
      "Epoch [8/10], Step [200/2272], Loss: 0.2533\n",
      "Epoch [8/10], Step [300/2272], Loss: 0.2591\n",
      "Epoch [8/10], Step [400/2272], Loss: 0.2588\n",
      "Epoch [8/10], Step [500/2272], Loss: 0.2649\n",
      "Epoch [8/10], Step [600/2272], Loss: 0.2658\n",
      "Epoch [8/10], Step [700/2272], Loss: 0.2554\n",
      "Epoch [8/10], Step [800/2272], Loss: 0.2564\n",
      "Epoch [8/10], Step [900/2272], Loss: 0.2587\n",
      "Epoch [8/10], Step [1000/2272], Loss: 0.2550\n",
      "Epoch [8/10], Step [1100/2272], Loss: 0.2668\n",
      "Epoch [8/10], Step [1200/2272], Loss: 0.2626\n",
      "Epoch [8/10], Step [1300/2272], Loss: 0.2523\n",
      "Epoch [8/10], Step [1400/2272], Loss: 0.2590\n",
      "Epoch [8/10], Step [1500/2272], Loss: 0.2577\n",
      "Epoch [8/10], Step [1600/2272], Loss: 0.2565\n",
      "Epoch [8/10], Step [1700/2272], Loss: 0.2604\n",
      "Epoch [8/10], Step [1800/2272], Loss: 0.2618\n",
      "Epoch [8/10], Step [1900/2272], Loss: 0.2566\n",
      "Epoch [8/10], Step [2000/2272], Loss: 0.2596\n",
      "Epoch [8/10], Step [2100/2272], Loss: 0.2589\n",
      "Epoch [8/10], Step [2200/2272], Loss: 0.2608\n",
      "Epoch [8/10], Training Loss: 0.0081, Validation Loss: 0.2699\n",
      "Starting epoch 9/10\n",
      "Epoch [9/10], Step [100/2272], Loss: 0.2541\n",
      "Epoch [9/10], Step [200/2272], Loss: 0.2591\n",
      "Epoch [9/10], Step [300/2272], Loss: 0.2573\n",
      "Epoch [9/10], Step [400/2272], Loss: 0.2589\n",
      "Epoch [9/10], Step [500/2272], Loss: 0.2631\n",
      "Epoch [9/10], Step [600/2272], Loss: 0.2516\n",
      "Epoch [9/10], Step [700/2272], Loss: 0.2505\n",
      "Epoch [9/10], Step [800/2272], Loss: 0.2644\n",
      "Epoch [9/10], Step [900/2272], Loss: 0.2573\n",
      "Epoch [9/10], Step [1000/2272], Loss: 0.2573\n",
      "Epoch [9/10], Step [1100/2272], Loss: 0.2545\n",
      "Epoch [9/10], Step [1200/2272], Loss: 0.2637\n",
      "Epoch [9/10], Step [1300/2272], Loss: 0.2578\n",
      "Epoch [9/10], Step [1400/2272], Loss: 0.2493\n",
      "Epoch [9/10], Step [1500/2272], Loss: 0.2575\n",
      "Epoch [9/10], Step [1600/2272], Loss: 0.2545\n",
      "Epoch [9/10], Step [1700/2272], Loss: 0.2538\n",
      "Epoch [9/10], Step [1800/2272], Loss: 0.2538\n",
      "Epoch [9/10], Step [1900/2272], Loss: 0.2512\n",
      "Epoch [9/10], Step [2000/2272], Loss: 0.2610\n",
      "Epoch [9/10], Step [2100/2272], Loss: 0.2511\n",
      "Epoch [9/10], Step [2200/2272], Loss: 0.2524\n",
      "Epoch [9/10], Training Loss: 0.0081, Validation Loss: 0.2655\n",
      "Starting epoch 10/10\n",
      "Epoch [10/10], Step [100/2272], Loss: 0.2504\n",
      "Epoch [10/10], Step [200/2272], Loss: 0.2544\n",
      "Epoch [10/10], Step [300/2272], Loss: 0.2526\n",
      "Epoch [10/10], Step [400/2272], Loss: 0.2516\n",
      "Epoch [10/10], Step [500/2272], Loss: 0.2579\n",
      "Epoch [10/10], Step [600/2272], Loss: 0.2462\n",
      "Epoch [10/10], Step [700/2272], Loss: 0.2558\n",
      "Epoch [10/10], Step [800/2272], Loss: 0.2555\n",
      "Epoch [10/10], Step [900/2272], Loss: 0.2580\n",
      "Epoch [10/10], Step [1000/2272], Loss: 0.2566\n",
      "Epoch [10/10], Step [1100/2272], Loss: 0.2569\n",
      "Epoch [10/10], Step [1200/2272], Loss: 0.2597\n",
      "Epoch [10/10], Step [1300/2272], Loss: 0.2504\n",
      "Epoch [10/10], Step [1400/2272], Loss: 0.2547\n",
      "Epoch [10/10], Step [1500/2272], Loss: 0.2580\n",
      "Epoch [10/10], Step [1600/2272], Loss: 0.2495\n",
      "Epoch [10/10], Step [1700/2272], Loss: 0.2548\n",
      "Epoch [10/10], Step [1800/2272], Loss: 0.2549\n",
      "Epoch [10/10], Step [1900/2272], Loss: 0.2573\n",
      "Epoch [10/10], Step [2000/2272], Loss: 0.2440\n",
      "Epoch [10/10], Step [2100/2272], Loss: 0.2492\n",
      "Epoch [10/10], Step [2200/2272], Loss: 0.2461\n",
      "Epoch [10/10], Training Loss: 0.0081, Validation Loss: 0.2653\n",
      "Training complete. Best Validation Loss: 0.26531503107398746\n",
      "Test Accuracy: 1310.68%\n"
     ]
    }
   ],
   "source": [
    "dense121 = models.densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "num_ftrs = dense121.classifier.in_features\n",
    "dense121.classifier = nn.Linear(num_ftrs, len(train_dataset_p.data_frame.columns) - 1)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(dense121.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(dense121, train_loader_p, val_loader_p, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Test the model\n",
    "test_model(dense121, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved at ./model_checkpoint_dense121_v1_10ep_p.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = \"./model_checkpoint_dense121_v1_10ep_p.pth\"\n",
    "\n",
    "store_model(dense121, optimizer, num_epochs + 1, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
