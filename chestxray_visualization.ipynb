{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for the Chest X-ray dataset\n",
    "\n",
    "Dataset originated from the paper of Wang et al. 2016 and extracted from the official NIH source  https://nihcc.app.box.com/v/ChestXray-NIHCC\n",
    "\n",
    "## Necessary instalations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install plotly --upgrade --user\n",
    "#!pip install pandas --upgrade --user\n",
    "#!pip install numpy --upgrade --user\n",
    "#!pip install scipy --upgrade --user\n",
    "#!pip install scikit-learn --upgrade --user\n",
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124 --user\n",
    "#!pip install holoviews plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import files for metadata analysis\n",
    "\n",
    "Get the files of metadata images so that an assesment can be made on the adequate preprocessing in order for the training to be fruitful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#we import the files from our system directly downloaded from the official NIH site\n",
    "bbox_data = pd.read_csv('./labels/Bbox_List_2017.csv', delimiter=',')\n",
    "metadata = pd.read_csv('./labels/Data_Entry_2017_v2020.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we output the head of the pandas dataset for the bboxes\n",
    "display(bbox_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema',  \n",
    "                 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'No Finding', 'Nodule',  \n",
    "                 'Pleural_Thickening', 'Pneumonia','Pneumothorax']\n",
    "\n",
    "positive_labels = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema',  \n",
    "                 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening',\n",
    "                 'Pneumonia','Pneumothorax']\n",
    "\n",
    "core8_labels = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltrate', 'Mass',\n",
    "                'Nodule', 'Pneumonia', 'Pneumothorax']\n",
    "\n",
    "\n",
    "for label in unique_labels:\n",
    "    metadata[label] = metadata['Finding Labels'].apply(lambda x: 1 if label in x else 0)\n",
    "\n",
    "bbox_data = bbox_data.drop(columns=['Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_data.rename(columns={\"Bbox [x\t\": \"x\",\"h]\": \"h\"})\n",
    "\n",
    "display(bbox_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(metadata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data\n",
    "\n",
    "Taking into account the consideration of patients of the same ID can't be split within test and train in order to mantain the test as a never seen set of images for the model (images from the same patient look alike and usally share some labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Get a group shuffle split object with the desired size\n",
    "gss = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
    "\n",
    "# Split the metadata indexes according to the group shuffle\n",
    "train_idx, test_idx = next(gss.split(metadata, groups=metadata['Patient ID']))\n",
    "\n",
    "# Create the pandas datasets using \n",
    "train_metadata = metadata.iloc[train_idx]\n",
    "test_metadata = metadata.iloc[test_idx]\n",
    "\n",
    "# Check the proportions of the resulting splits\n",
    "print(f\"Train set size: {len(train_metadata)}\")\n",
    "print(f\"Test set size: {len(test_metadata)}\")\n",
    "print(f\"Total set size: {len(train_metadata) + len(test_metadata)}\")\n",
    "print(f\"Number of unique patients in train set: {train_metadata['Patient ID'].nunique()}\")\n",
    "print(f\"Number of unique patients in test set: {test_metadata['Patient ID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical description of metadata\n",
    "\n",
    "Here we can see the mean and standard deviation of all variables in order to get an understanding of the numerical properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only the numerical columns\n",
    "numerical_cols = train_metadata.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "\n",
    "# Descriptive statistics for numerical variables\n",
    "display(train_metadata[numerical_cols].describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only the categorical columns\n",
    "categorical_cols = train_metadata.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Descriptive statistics for categorical variables\n",
    "display(train_metadata[categorical_cols].describe(include='all').T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "corr = train_metadata.corr(numeric_only=True)\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr, mask=mask, cmap='seismic',  center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2 = train_metadata[unique_labels].corr(numeric_only=True)\n",
    "mask = np.triu(np.ones_like(corr2, dtype=bool))\n",
    "plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr2, mask=mask, cmap='seismic',  center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple visualization\n",
    "\n",
    "Some simple graphs to understand the distribution and potential trends in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "data_big = ['Patient Age']\n",
    "train_metadata[data_big].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.violinplot(y='Patient Age', data=train_metadata, hue='Patient Gender', split=True, palette=\"Set2\")\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Patient Age')\n",
    "plt.title('Split Violin Plot of Patient Age by Gender')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = train_metadata[unique_labels].sum()\n",
    "\n",
    "label_counts = label_counts.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values, palette=\"viridis\")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Counts of Each Label')\n",
    "plt.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = train_metadata[positive_labels].sum()\n",
    "\n",
    "label_counts = label_counts.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values, palette=\"viridis\")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Counts of Each Label')\n",
    "plt.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Group by 'Patient ID' and take the maximum for each label to count each label per patient\n",
    "patient_label_counts = train_metadata.groupby('Patient ID')[positive_labels].max()\n",
    "\n",
    "# Step 2: Sum up the number of patients with each label\n",
    "label_counts_per_patient = patient_label_counts.sum()\n",
    "\n",
    "# Step 3: Sort the counts in descending order for plotting\n",
    "label_counts_per_patient = label_counts_per_patient.sort_values(ascending=False)\n",
    "\n",
    "# Step 4: Plotting the bar plot\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=label_counts_per_patient.index, y=label_counts_per_patient.values, palette=\"viridis\")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Counts (Patients)')\n",
    "plt.title('Counts of Each Label Across Patients')\n",
    "plt.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full GPT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Positive labels as provided\n",
    "positive_labels = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema',\n",
    "                   'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening',\n",
    "                   'Pneumonia', 'Pneumothorax']\n",
    "\n",
    "# Assuming 'Image Index' column has the image file names, and they are in the 'images/' folder\n",
    "image_folder = './images/'\n",
    "\n",
    "# Filter each label to get cases where only one illness is present (binary 1 for that label, 0 for others)\n",
    "single_label_images = []\n",
    "\n",
    "for label in positive_labels:\n",
    "    # Filter rows where only this label is 1 and all others are 0\n",
    "    filtered_df = train_metadata[(train_metadata[positive_labels].sum(axis=1) == 1) & (train_metadata[label] == 1)]\n",
    "    \n",
    "    # Get the image indices for these rows\n",
    "    image_indices = filtered_df['Image Index'].values\n",
    "    \n",
    "    # If there are any images, select one randomly\n",
    "    if len(image_indices) > 0:\n",
    "        chosen_image = random.choice(image_indices)\n",
    "        single_label_images.append(chosen_image)\n",
    "\n",
    "# Find an image with no findings (all labels are 0)\n",
    "no_findings_df = train_metadata[train_metadata[positive_labels].sum(axis=1) == 0]\n",
    "no_findings_image = None\n",
    "if len(no_findings_df) > 0:\n",
    "    no_findings_image = random.choice(no_findings_df['Image Index'].values)\n",
    "\n",
    "if no_findings_image:\n",
    "    single_label_images.append(no_findings_image)\n",
    "    positive_labels.append('No Findings')  # Add this to the labels for title display\n",
    "\n",
    "# Create a 3x5 grid to display the images\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))  # 3 rows, 5 columns\n",
    "\n",
    "# Flatten axes for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Load and display the images in a composite (grid) of 15 images\n",
    "for i, img_index in enumerate(single_label_images):\n",
    "    # Load the image from the folder\n",
    "    img_path = os.path.join(image_folder, img_index)\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    # Display the image in the grid in grayscale\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].set_title(positive_labels[i])\n",
    "    axes[i].axis('off')  # Hide axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Analysis of labels\n",
    "\n",
    "In order to futher understand the possible clusters within the data some PCA analysis will be done to reduce dimensionality of relevant data in order to try and forsee possible trends of the model once trained.\n",
    "\n",
    "Non-useful variables like id or image size are taken out of the PCA study. Since we are looking for clusters that are related through medical related features like the labels or patients age and gender trying to look for trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_metadata_pre = train_metadata.copy()\n",
    "\n",
    "# Non-useful variables like id or image size are taken out of the PCA study\n",
    "train_metadata_pre = train_metadata_pre.drop(columns=['Image Index', 'Finding Labels', 'Follow-up #',\n",
    "                                                      'Patient ID', 'View Position', \n",
    "                                                      'OriginalImage[Width', 'Height]',\n",
    "                                                      'OriginalImagePixelSpacing[x', 'y]',])\n",
    "\n",
    "# The variables selected are related to the medical state of the patient\n",
    "study_variables =  ['Patient Age','Patient Gender','Atelectasis', 'Cardiomegaly',\n",
    "                    'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', \n",
    "                    'Hernia', 'Infiltration', 'Mass', 'No Finding', 'Nodule', \n",
    "                    'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
    "\n",
    "# Mild preprocessing is needed to eliminate the last categorical variable\n",
    "train_metadata_pre['Patient Gender'] = train_metadata_pre['Patient Gender'].map({'M':0, 'F':1})\n",
    "\n",
    "train_metadata_sd = train_metadata_pre.copy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_metadata_sd[train_metadata_pre.columns] =  sc.fit_transform(train_metadata_pre)\n",
    "\n",
    "display(train_metadata_sd.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "myPCA = PCA().fit(train_metadata_sd)\n",
    "\n",
    "print(myPCA.explained_variance_ratio_)\n",
    "print()\n",
    "print(myPCA.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.plot(range(1,len(myPCA.singular_values_ )+1),myPCA.singular_values_ ,alpha=0.8,marker='.')\n",
    "y_label = plt.ylabel('Eigenvalues')\n",
    "x_label = plt.xlabel('Componentes')\n",
    "plt.title('Scree plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.plot(range(1,len(myPCA.explained_variance_ratio_ )+1),myPCA.explained_variance_ratio_ ,alpha=0.8,marker='.',label=\"Variancia Explicada\")\n",
    "y_label = plt.ylabel('Variancia explicada')\n",
    "x_label = plt.xlabel('Componentes')\n",
    "plt.plot(range(1,len(myPCA.explained_variance_ratio_ )+1),\n",
    "         np.cumsum(myPCA.explained_variance_ratio_),\n",
    "         c='red',marker='.',\n",
    "         label=\"Variancia explicada acumulativa\")\n",
    "plt.legend()\n",
    "plt.title('Porcentaje de variancia explicada por componente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(myPCA.components_, cmap='seismic',\n",
    "            xticklabels=list(train_metadata_pre.columns),\n",
    "            vmin=-np.max(np.abs(myPCA.components_)),\n",
    "            vmax=np.max(np.abs(myPCA.components_)),\n",
    "            annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalComponents = myPCA.transform(train_metadata_sd)\n",
    "\n",
    "loadings = myPCA.components_[:2].T * np.sqrt(myPCA.explained_variance_[:2])\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "for i, feature in enumerate(train_metadata_sd.columns):\n",
    "    plt.arrow(0, 0, loadings[i, 0], loadings[i, 1], color='r', alpha=0.5)\n",
    "    plt.text(loadings[i, 0] * 1.15, loadings[i, 1] * 1.15, feature, color='g', ha='center', va='center')\n",
    "\n",
    "plt.xlabel(f\"PC1 ({myPCA.explained_variance_ratio_[0]:.2%} variance)\")\n",
    "plt.ylabel(f\"PC2 ({myPCA.explained_variance_ratio_[1]:.2%} variance)\")\n",
    "plt.title('PCA Biplot (Using Precomputed PCA)')\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-distributed Stochastic Neighbor Embedding (t-SNE) \n",
    "\n",
    "Since PCA assumes that variables can be linearly combined our predominantly one hot encoded dataset holds no real interest since the values are binary instead of contiuous (which usually hold greater lineal combination).\n",
    "\n",
    "Because of that, t-SNE is a potentially better option since it is a non-linear dimensionality reduction technique since it focuses on preserving the local structure of the data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(train_metadata_sd)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(tsne_results[:, 0], tsne_results[:, 1], alpha=0.5)\n",
    "plt.title(\"t-SNE visualization\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base color mapping for individual labels\n",
    "base_labels = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema',  \n",
    "               'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'No Finding', 'Nodule',  \n",
    "               'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
    "\n",
    "# Generate a palette for the base labels\n",
    "palette = sns.color_palette(\"hsv\", len(base_labels))  # Using 'hsv' for distinct but gradient-like colors\n",
    "\n",
    "# Create a dictionary that maps each base label to a unique color\n",
    "base_color_mapping = dict(zip(base_labels, palette))\n",
    "\n",
    "# Function to blend colors for combined labels\n",
    "def blend_colors(label, base_color_mapping):\n",
    "    labels = label.split('|')  # Split the combined label into individual labels\n",
    "    if len(labels) == 1:\n",
    "        return base_color_mapping[labels[0]]  # Return the single color if it's not a combined label\n",
    "    \n",
    "    # Blend the colors for combined labels by averaging their RGB values\n",
    "    blended_color = np.mean([base_color_mapping[l] for l in labels if l in base_color_mapping], axis=0)\n",
    "    return blended_color\n",
    "\n",
    "# Extract combined labels\n",
    "combined_labels = train_metadata['Finding Labels']\n",
    "\n",
    "label_counts = combined_labels.value_counts()\n",
    "\n",
    "top_labels = label_counts.head(20).index\n",
    "\n",
    "\n",
    "filtered_indices = combined_labels.isin(top_labels)\n",
    "filtered_labels = combined_labels[filtered_indices]\n",
    "\n",
    "\n",
    "colors = [blend_colors(label, base_color_mapping) for label in filtered_labels]\n",
    "\n",
    "\n",
    "def plot_tsne_with_blended_colors(tsne_results, colors, top_labels, title):\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    scatter = plt.scatter(tsne_results[filtered_indices, 0], tsne_results[filtered_indices, 1],\n",
    "                          c=colors, alpha=0.7, s=10)\n",
    "\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=blend_colors(label, base_color_mapping),\n",
    "                          markersize=10, label=label) for label in top_labels]\n",
    "    \n",
    "    plt.legend(handles=handles, title='Labels', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"t-SNE Dimension 1\")\n",
    "    plt.ylabel(\"t-SNE Dimension 2\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_tsne_with_blended_colors(tsne_results, colors, top_labels, \"t-SNE with Blended Colors for Combined Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding Box Heatmap\n",
    "\n",
    "Let's generate a heatmap for each illness using the bbox to gain an understanding on where the pathologies are usually located from humans. This will help in the assesment of the Grad-CAM localization generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bbox_data['Finding Label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = (1024, 1024)\n",
    "\n",
    "heatmaps = {label: np.zeros(grid_size) for label in core8_labels}\n",
    "\n",
    "for idx, row in bbox_data.iterrows():\n",
    "    label = row['Finding Label']\n",
    "    x = row['Bbox [x']\n",
    "    y = row['y']\n",
    "    w = row['w']\n",
    "    h = row['h]']\n",
    "    \n",
    "    # Convert bbox to integer coordinates (assuming your bbox is float, adjust as needed)\n",
    "    x, y, w, h = int(float(x)), int(float(y)), int(float(w)), int(float(h))\n",
    "    \n",
    "    # Increment the heatmap grid cells for the given bounding box\n",
    "    if label in heatmaps:\n",
    "        heatmaps[label][y:y+h, x:x+w] += 1  # Increase the count in the bbox area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming core8_labels is defined and heatmaps dictionary contains data for each label\n",
    "\n",
    "# Number of labels to plot (core8 suggests 8 labels)\n",
    "num_labels = len(core8_labels)\n",
    "\n",
    "# Create a 2x4 grid for the 8 heatmaps\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 12))  # 2 rows, 4 columns\n",
    "\n",
    "# Flatten axes for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot heatmaps for each label\n",
    "for i, label in enumerate(core8_labels):\n",
    "    sns.heatmap(heatmaps[label], cmap=\"hot\", ax=axes[i], cbar=True)\n",
    "    axes[i].set_title(f\"Heatmap for {label}\", fontsize=14)\n",
    "    axes[i].set_xlabel(\"X Coordinate\", fontsize=10)\n",
    "    axes[i].set_ylabel(\"Y Coordinate\", fontsize=10)\n",
    "\n",
    "# Adjust layout to prevent overlapping of titles and labels\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-ocurrence matrix of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Step 1: Initialize an empty co-occurrence matrix\n",
    "co_occurrence_matrix = pd.DataFrame(0, index=positive_labels, columns=positive_labels)\n",
    "\n",
    "# Step 2: Compute co-occurrences between labels\n",
    "for i in range(len(train_metadata)):\n",
    "    # Get all labels present for the current patient (i.e., where one-hot encoding is 1)\n",
    "    present_labels = train_metadata.iloc[i][positive_labels].index[train_metadata.iloc[i][positive_labels] == 1].tolist()\n",
    "    \n",
    "    # Update the co-occurrence matrix for every pair of present labels\n",
    "    for label1 in present_labels:\n",
    "        for label2 in present_labels:\n",
    "            if label1 != label2:\n",
    "                co_occurrence_matrix.loc[label1, label2] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "\n",
    "edges = []\n",
    "max_value = co_occurrence_matrix.max().max() \n",
    "for label1 in co_occurrence_matrix.index:\n",
    "    for label2 in co_occurrence_matrix.columns:\n",
    "        if co_occurrence_matrix.loc[label1, label2] > 0:\n",
    "            edges.append((label1, label2, co_occurrence_matrix.loc[label1, label2],(co_occurrence_matrix.loc[label1, label2]/max_value)*10))\n",
    "\n",
    "chord_data = pd.DataFrame(edges, columns=['source', 'target', 'weight', 'edge_width'])\n",
    "\n",
    "chord = hv.Chord(chord_data)\n",
    "\n",
    "chord.opts(\n",
    "    opts.Chord(\n",
    "        cmap='Category20',\n",
    "        edge_cmap='Category20',\n",
    "        edge_color='source',\n",
    "        edge_line_width='edge_width',\n",
    "        labels='index',\n",
    "        node_size=15,\n",
    "        edge_alpha=0.5,\n",
    "        node_color='index',\n",
    "        title=\"Co-Occurrence Chord Diagram of Positive Labels\",\n",
    "        height=800, width=800\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the chord diagram\n",
    "chord"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
