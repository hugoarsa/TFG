{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing\n",
    "\n",
    "Now that all the metadata has been studied some testing with models from diferent sources and original code will be undergone in order to define some models to send to the boada environment.\n",
    "\n",
    "We will start slow with simple pre-trained models extracted directly from the pytorch environment and build from those up with the modifications that we want to study in the experimentation. Mainly the models tested will be ResNet (in some of it's variants) and some DensNet variants at first with the option of further models if everything goes to plan.\n",
    "\n",
    "Another objective would be to try to test the difference between transfer learning and full training from scratch, considering some other more sophisticated learning methods like one-shot if there is time.\n",
    "\n",
    "Finally some degree of localization will be accquired with the advancements of the paper from Selvaraju et al. of Grad-CAM.  Code will be recicled with the original paper code with the necessary modifications in order to apply it to the selected models of the project.\n",
    "\n",
    "\n",
    "## Preparing the split between test, train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Get the labels and read the original metadata\n",
    "labels = ['Atelectasis',\n",
    "          'Cardiomegaly',\n",
    "          'Consolidation',\n",
    "          'Edema',\n",
    "          'Effusion',\n",
    "          'Emphysema',\n",
    "          'Fibrosis',\n",
    "          'Hernia',\n",
    "          'Infiltration',\n",
    "          'Mass',\n",
    "          'Nodule',\n",
    "          'Pleural_Thickening',\n",
    "          'Pneumonia',\n",
    "          'Pneumothorax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('Data_Entry_2017_v2020.csv', delimiter=',')\n",
    "\n",
    "# Encode the labels with multi-label friendly encoding\n",
    "for label in labels:\n",
    "    metadata[label] = metadata['Finding Labels'].apply(lambda x: 1 if label in x else 0)\n",
    "\n",
    "metadata_positive = metadata[metadata['Finding Labels'] != 'No Finding']\n",
    "\n",
    "metadata = metadata.drop(columns=['Finding Labels', 'Follow-up #','Patient Age', 'Patient Gender', 'View Position', 'OriginalImage[Width','Height]', 'OriginalImagePixelSpacing[x', 'y]'])\n",
    "\n",
    "# Get the test train and val splits according to the patient ID so no patients end up split between groups\n",
    "gss_test = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
    "train_val_idx, test_idx = next(gss_test.split(metadata, groups=metadata['Patient ID']))\n",
    "\n",
    "train_val_metadata = metadata.iloc[train_val_idx]\n",
    "test_metadata = metadata.iloc[test_idx]\n",
    "\n",
    "gss_train_val = GroupShuffleSplit(test_size=0.125, n_splits=1, random_state=42)\n",
    "train_idx, val_idx = next(gss_train_val.split(train_val_metadata, groups=train_val_metadata['Patient ID']))\n",
    "\n",
    "train_metadata = train_val_metadata.iloc[train_idx]\n",
    "val_metadata = train_val_metadata.iloc[val_idx]\n",
    "\n",
    "\n",
    "# Drop the column of patient ID\n",
    "train_metadata = train_metadata.drop(columns=['Patient ID'])\n",
    "val_metadata = val_metadata.drop(columns=['Patient ID'])\n",
    "test_metadata = test_metadata.drop(columns=['Patient ID'])\n",
    "\n",
    "#Write all the new metadata as csv to load easier\n",
    "train_metadata.to_csv('./labels/train_metadata.csv', index=False)\n",
    "val_metadata.to_csv('./labels/val_metadata.csv', index=False)\n",
    "test_metadata.to_csv('./labels/test_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_positive.reset_index(drop=True, inplace=True)\n",
    "\n",
    "metadata_positive = metadata_positive.drop(columns=['Finding Labels', 'Follow-up #','Patient Age', 'Patient Gender', 'View Position', 'OriginalImage[Width','Height]', 'OriginalImagePixelSpacing[x', 'y]'])\n",
    "\n",
    "train_val_idx, test_idx = next(gss_test.split(metadata_positive, groups=metadata_positive['Patient ID']))\n",
    "\n",
    "train_val_metadata_p = metadata_positive.iloc[train_val_idx]\n",
    "test_metadata_p = metadata_positive.iloc[test_idx]\n",
    "\n",
    "train_idx, val_idx = next(gss_train_val.split(train_val_metadata_p, groups=train_val_metadata_p['Patient ID']))\n",
    "\n",
    "train_metadata_p = train_val_metadata_p.iloc[train_idx]\n",
    "val_metadata_p = train_val_metadata_p.iloc[val_idx]\n",
    "\n",
    "\n",
    "# Drop the column of patient ID\n",
    "train_metadata_p = train_metadata_p.drop(columns=['Patient ID'])\n",
    "val_metadata_p = val_metadata_p.drop(columns=['Patient ID'])\n",
    "test_metadata_p = test_metadata_p.drop(columns=['Patient ID'])\n",
    "\n",
    "\n",
    "#Write all the new metadata as csv to load easier\n",
    "train_metadata_p.to_csv('./labels/train_metadata_positive.csv', index=False)\n",
    "val_metadata_p.to_csv('./labels/val_metadata_positive.csv', index=False)\n",
    "test_metadata_p.to_csv('./labels/test_metadata_positive.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in terms of positives train: 36350, val: 5116, test: 10293 and total: 51759\n",
      "in terms of all train: 78873, val: 10953, test: 22294 and total: 112120\n"
     ]
    }
   ],
   "source": [
    "print(f'in terms of positives train: {len(train_metadata_p)}, val: {len(val_metadata_p)}, test: {len(test_metadata_p)} and total: {len(train_metadata_p) + len(test_metadata_p) + len(val_metadata_p) }')\n",
    "\n",
    "print(f'in terms of all train: {len(train_metadata)}, val: {len(val_metadata)}, test: {len(test_metadata)} and total: {len(train_metadata) + len(test_metadata) + len(val_metadata) }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset definition and load (dataset.py)\n",
    "\n",
    "We define the dataset and load from the data entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "class ChestXRay(Dataset):\n",
    "    def __init__(self, df_dir, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df_dir: Path to the csv file with image names and labels.\n",
    "            image_dir: Directory with all the images with the labels.\n",
    "            transform: Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(df_dir)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.size = len(self.data_frame)\n",
    "        self.labels = np.array(self.data_frame.iloc[:, 1:])\n",
    "        self.images = self.data_frame.iloc[:,0]\n",
    "\n",
    "        #cambiar esta mier\n",
    "        self.pred_label =  {'Atelectasis': 0,\n",
    "                            'Cardiomegaly': 1,\n",
    "                            'Consolidation': 2,\n",
    "                            'Edema': 3,\n",
    "                            'Effusion': 4,\n",
    "                            'Emphysema': 5,\n",
    "                            'Fibrosis': 6,\n",
    "                            'Hernia': 7,\n",
    "                            'Infiltration': 8,\n",
    "                            'Mass': 9,\n",
    "                            'Nodule': 10,\n",
    "                            'Pleural_Thickening': 11,\n",
    "                            'Pneumonia': 12,\n",
    "                            'Pneumothorax': 13}\n",
    "        \n",
    "        self.classes = ['Atelectasis',\n",
    "                        'Cardiomegaly',\n",
    "                        'Consolidation',\n",
    "                        'Edema',\n",
    "                        'Effusion',\n",
    "                        'Emphysema',\n",
    "                        'Fibrosis',\n",
    "                        'Hernia',\n",
    "                        'Infiltration',\n",
    "                        'Mass',\n",
    "                        'Nodule',\n",
    "                        'Pleural_Thickening',\n",
    "                        'Pneumonia',\n",
    "                        'Pneumothorax']\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image path\n",
    "        img_name = os.path.join(self.image_dir, self.images.iloc[idx])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        \n",
    "        # Get labels\n",
    "        labels = np.array(self.labels[idx])\n",
    "        \n",
    "        # Check for any object types (invalid data)\n",
    "        if not np.issubdtype(labels.dtype, np.number):\n",
    "            raise TypeError(f\"Non-numeric label detected at index {idx}: {labels}\")\n",
    "        \n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        image = np.array(image)\n",
    "        \n",
    "        return {'image': image, 'labels': labels}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various functions (utils.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                 [0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "def make_data_loaders(train_csv,val_csv,image_dir,batch_size,image_size):\n",
    "    \n",
    "\n",
    "    train_transforms = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "    ])\n",
    "\n",
    "    val_transforms = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "    ])\n",
    "\n",
    "    train_dataset = ChestXRay(df_dir=train_csv, image_dir=image_dir, transform=train_transforms)\n",
    "    val_dataset = ChestXRay(df_dir=val_csv, image_dir=image_dir, transform=val_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "\n",
    "    return dataloaders, {'train':len(train_dataset),'val':len(val_dataset)}, train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "def LoadModel(checkpoint_file, model, optimizer, epoch_inti, num_GPU):\n",
    "    '''\n",
    "    The loads the model, optimizer, current epoch, and current validation AUC from the checkpoint location provided.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    checkpoint_file: (str) the location of the model in s/m\n",
    "    model: PyTorch model\n",
    "    optimizer: PyTorch optimizer\n",
    "    epoch_inti: current epoch\n",
    "    num_GPU : (int) number of GPUs that are being used\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Returns the model, optimizer, epoch_inti, best_auc_ave from the saved location.\n",
    "    '''\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    epoch_inti = checkpoint['epoch']\n",
    "    if num_GPU > 1:\n",
    "        model.module.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return model, optimizer, epoch_inti\n",
    "\n",
    "\n",
    "def SaveModel(model, optimizer, epoch, file_name, num_GPU):\n",
    "    \"\"\"\n",
    "    Save the model parameters, optimizer, best_AUC\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch : (int) current epoch\n",
    "    model : Pytorch model to save\n",
    "    optimizer : Pytorch optimzer to save\n",
    "    file_name : (str) location where the model needed to be saved\n",
    "    num_GPU : (int) number of GPUs that are being used\n",
    "\n",
    "    \"\"\"\n",
    "    if num_GPU > 1:\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.module.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "    else:\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "    torch.save(state, file_name)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, steps=1000, patience=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())  # Keep track of best model weights\n",
    "    best_val_loss = float('inf')  # Initialize best validation loss as infinity\n",
    "    epochs_without_improvement = 0  # Counter for epochs without improvement\n",
    "\n",
    "    # Define the learning rate scheduler (reduce LR on plateau)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "    val_losses = []  # List to store validation losses for plotting\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        print(f'Starting epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "        # Training loop\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            if i >= steps:  # Break after the defined number of steps\n",
    "                break\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['labels'].to(device).float()\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation at the end of each epoch\n",
    "        val_loss = validate_model(model, val_loader, criterion)\n",
    "        val_losses.append(val_loss)  # Log the validation loss\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss  # Update best validation loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())  # Save the best model weights\n",
    "            epochs_without_improvement = 0  # Reset counter\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f'No improvement in validation loss for {epochs_without_improvement} epoch(s).')\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f'Early stopping after {epochs_without_improvement} epochs without improvement.')\n",
    "            break\n",
    "\n",
    "        # Update the learning rate based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    # Load best model weights before returning\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print('Training complete. Best Validation Loss:', best_val_loss)\n",
    "    \n",
    "    return model, val_losses  # Return the model and the validation losses\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['labels'].to(device).float()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(val_loader)  # Return average validation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test function\n",
    "\n",
    "Test function that generates the testing values that are necessary for the evaluation of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    threshold = 0.5  # Threshold for multi-label classification\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            predicted = (torch.sigmoid(outputs) > threshold).float()\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m get_optimizer(parameters,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m,learning_rate)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet18\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, steps, patience)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m steps:  \u001b[38;5;66;03m# Break after the defined number of steps\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[5], line 59\u001b[0m, in \u001b[0;36mChestXRay.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# Get image path\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     img_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages\u001b[38;5;241m.\u001b[39miloc[idx])\n\u001b[1;32m---> 59\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# Get labels\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx])\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\PIL\\Image.py:995\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    993\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m--> 995\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    997\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\PIL\\ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet18_Weights, ResNet50_Weights, DenseNet121_Weights\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "iter_per_epoch = 1000\n",
    "image_size = 244\n",
    "\n",
    "# Paths\n",
    "train_csv = './labels/train_metadata_positive.csv'\n",
    "val_csv = './labels/val_metadata_positive.csv'\n",
    "image_dir = '../resized_images'\n",
    "num_classes = 14\n",
    "\n",
    "train_p_csv = './labels/train_metadata_positive.csv'\n",
    "val_p_csv = './labels/val_metadata_positive.csv'\n",
    "\n",
    "# Data Loaders\n",
    "\n",
    "dataloaders, dataset_sizes, class_names = make_data_loaders(train_csv,val_csv,image_dir,batch_size,image_size)\n",
    "\n",
    "# Model\n",
    "resnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "parameters = resnet18.parameters()\n",
    "optimizer = get_optimizer(parameters,'Adam',learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(resnet18, dataloaders['train'], dataloaders['val'], criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for the best Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Adadelta, Adam, RMSprop, AdamW\n",
    "\n",
    "def get_optimizer(params, optimizer, lr=1e-4, momentum=0.9, weight_decay=0.0):\n",
    "    \"\"\"\n",
    "    Loads and returns the optimizer.\n",
    "    \"\"\"\n",
    "    if optimizer == 'SGD':\n",
    "        return SGD(params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    elif optimizer == 'SGD_Nesterov':\n",
    "        return SGD(params, lr=lr, momentum=momentum, weight_decay=weight_decay, nesterov=True)\n",
    "    elif optimizer == 'Adadelta':\n",
    "        return Adadelta(params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer == 'Adam':\n",
    "        return Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer == 'AdamW':\n",
    "        return AdamW(params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        return RMSprop(params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise Exception('Unknown optimizer : {}'.format(optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "def test_optimizer(opt_name, val_losses_storage):\n",
    "    # Hyperparameters\n",
    "    batch_size = 16\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 25\n",
    "    steps_per_epoch = 500\n",
    "    image_size = 256\n",
    "    num_classes = 14\n",
    "\n",
    "    # Paths\n",
    "    train_csv = './labels/train_metadata_positive.csv'\n",
    "    val_csv = './labels/val_metadata_positive.csv'\n",
    "    image_dir = './resized_images'\n",
    "\n",
    "    # Data Loaders\n",
    "    dataloaders, dataset_sizes, class_names = make_data_loaders(train_csv, val_csv, image_dir, batch_size, image_size)\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    print(f'Testing optimizer: {opt_name}')\n",
    "\n",
    "    # Model initialization\n",
    "    model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    # Get the optimizer\n",
    "    parameters = model.parameters()\n",
    "    optimizer = get_optimizer(parameters, opt_name, learning_rate)\n",
    "\n",
    "    # Train the model and get validation losses\n",
    "    _, val_losses = train_model(model, dataloaders['train'], dataloaders['val'], criterion, optimizer, num_epochs, steps_per_epoch)\n",
    "\n",
    "    # Store validation losses for this optimizer\n",
    "    val_losses_storage[opt_name] = val_losses\n",
    "\n",
    "    return val_losses_storage\n",
    "\n",
    "def plot_losses(val_losses_per_optimizer):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for opt_name, val_losses in val_losses_per_optimizer.items():\n",
    "        plt.plot(val_losses, label=f'{opt_name}')\n",
    "\n",
    "    plt.title('Validation Loss vs Epochs for Different Optimizers')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses_storage = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimizer: SGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/25\n",
      "Epoch [1/25], Validation Loss: 0.3038\n",
      "Starting epoch 2/25\n",
      "Epoch [2/25], Validation Loss: 0.2992\n",
      "Starting epoch 3/25\n",
      "Epoch [3/25], Validation Loss: 0.2963\n",
      "Starting epoch 4/25\n",
      "Epoch [4/25], Validation Loss: 0.2939\n",
      "Starting epoch 5/25\n",
      "Epoch [5/25], Validation Loss: 0.2927\n",
      "Starting epoch 6/25\n",
      "Epoch [6/25], Validation Loss: 0.2910\n",
      "Starting epoch 7/25\n",
      "Epoch [7/25], Validation Loss: 0.2895\n",
      "Starting epoch 8/25\n",
      "Epoch [8/25], Validation Loss: 0.2874\n",
      "Starting epoch 9/25\n",
      "Epoch [9/25], Validation Loss: 0.2855\n",
      "Starting epoch 10/25\n",
      "Epoch [10/25], Validation Loss: 0.2844\n",
      "Starting epoch 11/25\n",
      "Epoch [11/25], Validation Loss: 0.2836\n",
      "Starting epoch 12/25\n",
      "Epoch [12/25], Validation Loss: 0.2828\n",
      "Starting epoch 13/25\n",
      "Epoch [13/25], Validation Loss: 0.2824\n",
      "Starting epoch 14/25\n",
      "Epoch [14/25], Validation Loss: 0.2797\n",
      "Starting epoch 15/25\n",
      "Epoch [15/25], Validation Loss: 0.2800\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 16/25\n",
      "Epoch [16/25], Validation Loss: 0.2790\n",
      "Starting epoch 17/25\n",
      "Epoch [17/25], Validation Loss: 0.2787\n",
      "Starting epoch 18/25\n",
      "Epoch [18/25], Validation Loss: 0.2771\n",
      "Starting epoch 19/25\n",
      "Epoch [19/25], Validation Loss: 0.2772\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 20/25\n",
      "Epoch [20/25], Validation Loss: 0.2763\n",
      "Starting epoch 21/25\n",
      "Epoch [21/25], Validation Loss: 0.2749\n",
      "Starting epoch 22/25\n",
      "Epoch [22/25], Validation Loss: 0.2763\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 23/25\n",
      "Epoch [23/25], Validation Loss: 0.2747\n",
      "Starting epoch 24/25\n",
      "Epoch [24/25], Validation Loss: 0.2745\n",
      "Starting epoch 25/25\n",
      "Epoch [25/25], Validation Loss: 0.2744\n",
      "Training complete. Best Validation Loss: 0.27438209955580534\n"
     ]
    }
   ],
   "source": [
    "# Testing SGD optimizer\n",
    "val_losses_storage = test_optimizer('SGD', val_losses_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimizer: SGD_Nesterov\n",
      "Starting epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Validation Loss: 0.3039\n",
      "Starting epoch 2/25\n",
      "Epoch [2/25], Validation Loss: 0.2996\n",
      "Starting epoch 3/25\n",
      "Epoch [3/25], Validation Loss: 0.2957\n",
      "Starting epoch 4/25\n",
      "Epoch [4/25], Validation Loss: 0.2925\n",
      "Starting epoch 5/25\n",
      "Epoch [5/25], Validation Loss: 0.2904\n",
      "Starting epoch 6/25\n",
      "Epoch [6/25], Validation Loss: 0.2898\n",
      "Starting epoch 7/25\n",
      "Epoch [7/25], Validation Loss: 0.2862\n",
      "Starting epoch 8/25\n",
      "Epoch [8/25], Validation Loss: 0.2855\n",
      "Starting epoch 9/25\n",
      "Epoch [9/25], Validation Loss: 0.2839\n",
      "Starting epoch 10/25\n",
      "Epoch [10/25], Validation Loss: 0.2832\n",
      "Starting epoch 11/25\n",
      "Epoch [11/25], Validation Loss: 0.2822\n",
      "Starting epoch 12/25\n",
      "Epoch [12/25], Validation Loss: 0.2805\n",
      "Starting epoch 13/25\n",
      "Epoch [13/25], Validation Loss: 0.2795\n",
      "Starting epoch 14/25\n",
      "Epoch [14/25], Validation Loss: 0.2787\n",
      "Starting epoch 15/25\n",
      "Epoch [15/25], Validation Loss: 0.2770\n",
      "Starting epoch 16/25\n",
      "Epoch [16/25], Validation Loss: 0.2768\n",
      "Starting epoch 17/25\n",
      "Epoch [17/25], Validation Loss: 0.2767\n",
      "Starting epoch 18/25\n",
      "Epoch [18/25], Validation Loss: 0.2763\n",
      "Starting epoch 19/25\n",
      "Epoch [19/25], Validation Loss: 0.2754\n",
      "Starting epoch 20/25\n",
      "Epoch [20/25], Validation Loss: 0.2745\n",
      "Starting epoch 21/25\n",
      "Epoch [21/25], Validation Loss: 0.2736\n",
      "Starting epoch 22/25\n",
      "Epoch [22/25], Validation Loss: 0.2736\n",
      "Starting epoch 23/25\n",
      "Epoch [23/25], Validation Loss: 0.2729\n",
      "Starting epoch 24/25\n",
      "Epoch [24/25], Validation Loss: 0.2722\n",
      "Starting epoch 25/25\n",
      "Epoch [25/25], Validation Loss: 0.2722\n",
      "Training complete. Best Validation Loss: 0.2722050901968032\n"
     ]
    }
   ],
   "source": [
    "# Testing SGD optimizer\n",
    "val_losses_storage = test_optimizer('SGD_Nesterov', val_losses_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimizer: Adadelta\n",
      "Starting epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Validation Loss: 0.4281\n",
      "Starting epoch 2/25\n",
      "Epoch [2/25], Validation Loss: 0.3374\n",
      "Starting epoch 3/25\n",
      "Epoch [3/25], Validation Loss: 0.3157\n",
      "Starting epoch 4/25\n",
      "Epoch [4/25], Validation Loss: 0.3103\n",
      "Starting epoch 5/25\n",
      "Epoch [5/25], Validation Loss: 0.3081\n",
      "Starting epoch 6/25\n",
      "Epoch [6/25], Validation Loss: 0.3068\n",
      "Starting epoch 7/25\n",
      "Epoch [7/25], Validation Loss: 0.3060\n",
      "Starting epoch 8/25\n",
      "Epoch [8/25], Validation Loss: 0.3054\n",
      "Starting epoch 9/25\n",
      "Epoch [9/25], Validation Loss: 0.3049\n",
      "Starting epoch 10/25\n",
      "Epoch [10/25], Validation Loss: 0.3043\n",
      "Starting epoch 11/25\n",
      "Epoch [11/25], Validation Loss: 0.3037\n",
      "Starting epoch 12/25\n",
      "Epoch [12/25], Validation Loss: 0.3031\n",
      "Starting epoch 13/25\n",
      "Epoch [13/25], Validation Loss: 0.3029\n",
      "Starting epoch 14/25\n",
      "Epoch [14/25], Validation Loss: 0.3024\n",
      "Starting epoch 15/25\n",
      "Epoch [15/25], Validation Loss: 0.3021\n",
      "Starting epoch 16/25\n",
      "Epoch [16/25], Validation Loss: 0.3016\n",
      "Starting epoch 17/25\n",
      "Epoch [17/25], Validation Loss: 0.3013\n",
      "Starting epoch 18/25\n",
      "Epoch [18/25], Validation Loss: 0.3008\n",
      "Starting epoch 19/25\n",
      "Epoch [19/25], Validation Loss: 0.3004\n",
      "Starting epoch 20/25\n",
      "Epoch [20/25], Validation Loss: 0.3001\n",
      "Starting epoch 21/25\n",
      "Epoch [21/25], Validation Loss: 0.2997\n",
      "Starting epoch 22/25\n",
      "Epoch [22/25], Validation Loss: 0.2994\n",
      "Starting epoch 23/25\n",
      "Epoch [23/25], Validation Loss: 0.2990\n",
      "Starting epoch 24/25\n",
      "Epoch [24/25], Validation Loss: 0.2989\n",
      "Starting epoch 25/25\n",
      "Epoch [25/25], Validation Loss: 0.2983\n",
      "Training complete. Best Validation Loss: 0.2983213088940829\n"
     ]
    }
   ],
   "source": [
    "# Testing SGD optimizer\n",
    "val_losses_storage = test_optimizer('Adadelta', val_losses_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimizer: Adam\n",
      "Starting epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Validation Loss: 0.3198\n",
      "Starting epoch 2/25\n",
      "Epoch [2/25], Validation Loss: 0.3067\n",
      "Starting epoch 3/25\n",
      "Epoch [3/25], Validation Loss: 0.3009\n",
      "Starting epoch 4/25\n",
      "Epoch [4/25], Validation Loss: 0.2993\n",
      "Starting epoch 5/25\n",
      "Epoch [5/25], Validation Loss: 0.2936\n",
      "Starting epoch 6/25\n",
      "Epoch [6/25], Validation Loss: 0.2985\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 7/25\n",
      "Epoch [7/25], Validation Loss: 0.3047\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Starting epoch 8/25\n",
      "Epoch [8/25], Validation Loss: 0.2973\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Starting epoch 9/25\n",
      "Epoch [9/25], Validation Loss: 0.2920\n",
      "Starting epoch 10/25\n",
      "Epoch [10/25], Validation Loss: 0.2862\n",
      "Starting epoch 11/25\n",
      "Epoch [11/25], Validation Loss: 0.2864\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 12/25\n",
      "Epoch [12/25], Validation Loss: 0.2873\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Starting epoch 13/25\n",
      "Epoch [13/25], Validation Loss: 0.2798\n",
      "Starting epoch 14/25\n",
      "Epoch [14/25], Validation Loss: 0.2829\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 15/25\n",
      "Epoch [15/25], Validation Loss: 0.2805\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Starting epoch 16/25\n",
      "Epoch [16/25], Validation Loss: 0.2843\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Starting epoch 17/25\n",
      "Epoch [17/25], Validation Loss: 0.2887\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Starting epoch 18/25\n",
      "Epoch [18/25], Validation Loss: 0.2715\n",
      "Starting epoch 19/25\n",
      "Epoch [19/25], Validation Loss: 0.2703\n",
      "Starting epoch 20/25\n",
      "Epoch [20/25], Validation Loss: 0.2694\n",
      "Starting epoch 21/25\n",
      "Epoch [21/25], Validation Loss: 0.2689\n",
      "Starting epoch 22/25\n",
      "Epoch [22/25], Validation Loss: 0.2694\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 23/25\n",
      "Epoch [23/25], Validation Loss: 0.2708\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Starting epoch 24/25\n",
      "Epoch [24/25], Validation Loss: 0.2689\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Starting epoch 25/25\n",
      "Epoch [25/25], Validation Loss: 0.2678\n",
      "Training complete. Best Validation Loss: 0.267797968769446\n"
     ]
    }
   ],
   "source": [
    "# Testing SGD optimizer\n",
    "val_losses_storage = test_optimizer('Adam', val_losses_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimizer: AdamW\n",
      "Starting epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Validation Loss: 0.3027\n",
      "Starting epoch 2/25\n",
      "Epoch [2/25], Validation Loss: 0.3036\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 3/25\n",
      "Epoch [3/25], Validation Loss: 0.3138\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Starting epoch 4/25\n",
      "Epoch [4/25], Validation Loss: 0.2992\n",
      "Starting epoch 5/25\n",
      "Epoch [5/25], Validation Loss: 0.2934\n",
      "Starting epoch 6/25\n",
      "Epoch [6/25], Validation Loss: 0.2937\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 7/25\n",
      "Epoch [7/25], Validation Loss: 0.2941\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Starting epoch 8/25\n",
      "Epoch [8/25], Validation Loss: 0.2925\n",
      "Starting epoch 9/25\n",
      "Epoch [9/25], Validation Loss: 0.2901\n",
      "Starting epoch 10/25\n",
      "Epoch [10/25], Validation Loss: 0.2952\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 11/25\n",
      "Epoch [11/25], Validation Loss: 0.3069\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Starting epoch 12/25\n",
      "Epoch [12/25], Validation Loss: 0.3147\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Starting epoch 13/25\n",
      "Epoch [13/25], Validation Loss: 0.2841\n",
      "Starting epoch 14/25\n",
      "Epoch [14/25], Validation Loss: 0.2813\n",
      "Starting epoch 15/25\n",
      "Epoch [15/25], Validation Loss: 0.2830\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 16/25\n",
      "Epoch [16/25], Validation Loss: 0.2859\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Starting epoch 17/25\n",
      "Epoch [17/25], Validation Loss: 0.2780\n",
      "Starting epoch 18/25\n",
      "Epoch [18/25], Validation Loss: 0.2803\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 19/25\n",
      "Epoch [19/25], Validation Loss: 0.2800\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Starting epoch 20/25\n",
      "Epoch [20/25], Validation Loss: 0.2782\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Starting epoch 21/25\n",
      "Epoch [21/25], Validation Loss: 0.2759\n",
      "Starting epoch 22/25\n",
      "Epoch [22/25], Validation Loss: 0.2768\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 23/25\n",
      "Epoch [23/25], Validation Loss: 0.2741\n",
      "Starting epoch 24/25\n",
      "Epoch [24/25], Validation Loss: 0.2748\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 25/25\n",
      "Epoch [25/25], Validation Loss: 0.2778\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Training complete. Best Validation Loss: 0.27412701891735197\n"
     ]
    }
   ],
   "source": [
    "# Testing SGD optimizer\n",
    "val_losses_storage = test_optimizer('AdamW', val_losses_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimizer: RMSprop\n",
      "Starting epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hugoa\\anaconda3\\envs\\cuda_dev_1\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Validation Loss: 0.3205\n",
      "Starting epoch 2/25\n",
      "Epoch [2/25], Validation Loss: 0.3089\n",
      "Starting epoch 3/25\n",
      "Epoch [3/25], Validation Loss: 0.5201\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 4/25\n",
      "Epoch [4/25], Validation Loss: 0.3112\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Starting epoch 5/25\n",
      "Epoch [5/25], Validation Loss: 0.3015\n",
      "Starting epoch 6/25\n",
      "Epoch [6/25], Validation Loss: 0.3050\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 7/25\n",
      "Epoch [7/25], Validation Loss: 0.2999\n",
      "Starting epoch 8/25\n",
      "Epoch [8/25], Validation Loss: 0.3001\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 9/25\n",
      "Epoch [9/25], Validation Loss: 0.3000\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Starting epoch 10/25\n",
      "Epoch [10/25], Validation Loss: 0.3029\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Starting epoch 11/25\n",
      "Epoch [11/25], Validation Loss: 0.3028\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Starting epoch 12/25\n",
      "Epoch [12/25], Validation Loss: 0.2957\n",
      "Starting epoch 13/25\n",
      "Epoch [13/25], Validation Loss: 0.2949\n",
      "Starting epoch 14/25\n",
      "Epoch [14/25], Validation Loss: 0.2950\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 15/25\n",
      "Epoch [15/25], Validation Loss: 0.2954\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Starting epoch 16/25\n",
      "Epoch [16/25], Validation Loss: 0.2951\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Starting epoch 17/25\n",
      "Epoch [17/25], Validation Loss: 0.2944\n",
      "Starting epoch 18/25\n",
      "Epoch [18/25], Validation Loss: 0.2943\n",
      "Starting epoch 19/25\n",
      "Epoch [19/25], Validation Loss: 0.2945\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 20/25\n",
      "Epoch [20/25], Validation Loss: 0.2940\n",
      "Starting epoch 21/25\n",
      "Epoch [21/25], Validation Loss: 0.2969\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 22/25\n",
      "Epoch [22/25], Validation Loss: 0.2939\n",
      "Starting epoch 23/25\n",
      "Epoch [23/25], Validation Loss: 0.2948\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Starting epoch 24/25\n",
      "Epoch [24/25], Validation Loss: 0.2939\n",
      "Starting epoch 25/25\n",
      "Epoch [25/25], Validation Loss: 0.2945\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Training complete. Best Validation Loss: 0.2938777937553823\n"
     ]
    }
   ],
   "source": [
    "# Testing SGD optimizer\n",
    "val_losses_storage = test_optimizer('RMSprop', val_losses_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(val_losses_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for the best learning rate and batch size combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def train_model_logs(model, train_loader, val_loader, criterion, optimizer, num_epochs, steps=1000, patience=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    # Define the learning rate scheduler (reduce LR on plateau)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "\n",
    "    val_losses = []  # List to store validation losses for plotting\n",
    "    val_auc_scores = []  # List to store AUC scores for each epoch\n",
    "    time_per_epoch = []  # List to store elapsed time per epoch\n",
    "    lr_per_epoch = [] # List of Lr evlution per epoch\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()  # Start time for epoch timing\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        print(f'Starting epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "        # Training loop\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            #print(i)\n",
    "            if i >= steps:\n",
    "                #print('break')\n",
    "                break\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['labels'].to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        elapsed_time_train = time.time() - start_time  # Calculate elapsed time\n",
    "        \n",
    "\n",
    "        # Validation at the end of each epoch\n",
    "        start_time = time.time()  # Start time for epoch timing\n",
    "        val_loss, val_auc = validate_model_logs(model, val_loader, criterion)\n",
    "\n",
    "        elapsed_time_val = time.time() - start_time  # Calculate elapsed time\n",
    "\n",
    "        val_losses.append(val_loss)  # Log the validation loss\n",
    "        val_auc_scores.append(val_auc)  # Log the AUC scores\n",
    "        time_per_epoch.append((elapsed_time_train,elapsed_time_val))  # Epoch elapsed time\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, AUC: {val_auc:.4f}, Time on train: {elapsed_time_train:.2f}s, Time on val: {elapsed_time_val:.2f}s')\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f'No improvement in validation loss for {epochs_without_improvement} epoch(s).')\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f'Early stopping after {epochs_without_improvement} epochs without improvement.')\n",
    "            break\n",
    "\n",
    "        # Update the learning rate based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        new_lr = scheduler.get_last_lr()\n",
    "        lr_per_epoch.append(new_lr)\n",
    "        print(f'Learning rate is updated to {new_lr}')\n",
    "\n",
    "\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print('Training complete. Best Validation Loss:', best_val_loss)\n",
    "\n",
    "    return model, val_losses, val_auc_scores, time_per_epoch  # Return the model and all logs\n",
    "\n",
    "def validate_model_logs(model, val_loader, criterion):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['labels'].to(device).float()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader)  # Average validation loss\n",
    "    all_outputs = np.concatenate(all_outputs)  # Concatenate outputs for AUC calculation\n",
    "    all_labels = np.concatenate(all_labels)  # Concatenate labels for AUC calculation\n",
    "\n",
    "    # Calculate AUC for each label\n",
    "    auc_scores = []\n",
    "    for i in range(all_labels.shape[1]):  # Assuming all_labels is shape [num_samples, num_labels]\n",
    "        if np.unique(all_labels[:, i]).size > 1:  # Check for both classes in the label\n",
    "            auc = roc_auc_score(all_labels[:, i], all_outputs[:, i])\n",
    "            auc_scores.append(auc)\n",
    "        else:\n",
    "            auc_scores.append(np.nan)  # If only one class is present, AUC is undefined\n",
    "\n",
    "    mean_auc = np.nanmean(auc_scores)  # Calculate mean AUC ignoring NaN values\n",
    "    return val_loss, mean_auc  # Return average validation loss and mean AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [32, 64, 128, 256, 512]\n",
    "learning_rates = [1e-4, 5e-4, 1e-3, 1e-2, 1e-1]\n",
    "num_epochs = 15\n",
    "iter_per_epoch = 8192\n",
    "image_size = 256\n",
    "num_classes = 14\n",
    "\n",
    "# Paths\n",
    "train_csv = './labels/train_metadata_positive.csv'\n",
    "val_csv = './labels/val_metadata_positive.csv'\n",
    "image_dir = '../resized_images'\n",
    "\n",
    "# Storage matrices\n",
    "final_val_losses = np.zeros((len(batch_sizes), len(learning_rates)))\n",
    "final_val_aucs = np.zeros((len(batch_sizes), len(learning_rates)))\n",
    "epoch_times_matrix = np.zeros((len(batch_sizes), len(learning_rates)))\n",
    "\n",
    "# Function to map batch_size and lr indices\n",
    "def get_index(batch_size, lr):\n",
    "    batch_index = batch_sizes.index(batch_size)\n",
    "    lr_index = learning_rates.index(lr)\n",
    "    return batch_index, lr_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test with batch size = 32 and learning rate = 0.0001\n",
      "The final epoch iterations are 256.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.2833, AUC: 0.7107, Time on train: 39.61s, Time on val: 15.77s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.2798, AUC: 0.7309, Time on train: 38.79s, Time on val: 13.45s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.2754, AUC: 0.7404, Time on train: 38.10s, Time on val: 13.45s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.2706, AUC: 0.7574, Time on train: 37.63s, Time on val: 13.30s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.2675, AUC: 0.7584, Time on train: 37.27s, Time on val: 13.33s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.2697, AUC: 0.7619, Time on train: 37.12s, Time on val: 13.47s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.2656, AUC: 0.7661, Time on train: 36.88s, Time on val: 13.60s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.2691, AUC: 0.7656, Time on train: 36.89s, Time on val: 13.52s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2659, AUC: 0.7705, Time on train: 36.71s, Time on val: 13.55s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2655, AUC: 0.7710, Time on train: 36.69s, Time on val: 13.41s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2684, AUC: 0.7713, Time on train: 36.54s, Time on val: 13.28s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2670, AUC: 0.7680, Time on train: 36.54s, Time on val: 13.45s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2670, AUC: 0.7683, Time on train: 36.48s, Time on val: 13.37s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2647, AUC: 0.7734, Time on train: 36.41s, Time on val: 13.52s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2625, AUC: 0.7761, Time on train: 36.36s, Time on val: 13.28s\n",
      "Learning rate is updated to [0.0001]\n",
      "Training complete. Best Validation Loss: 0.26252185050398114\n",
      "Starting test with batch size = 32 and learning rate = 0.0005\n",
      "The final epoch iterations are 256.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.2970, AUC: 0.6557, Time on train: 36.26s, Time on val: 13.41s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.2894, AUC: 0.6976, Time on train: 36.32s, Time on val: 13.37s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.2842, AUC: 0.7189, Time on train: 36.28s, Time on val: 13.46s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.3180, AUC: 0.7228, Time on train: 36.33s, Time on val: 13.33s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.3004, AUC: 0.7253, Time on train: 36.25s, Time on val: 13.36s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.2830, AUC: 0.7398, Time on train: 36.31s, Time on val: 13.40s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.2758, AUC: 0.7375, Time on train: 36.31s, Time on val: 13.54s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.2738, AUC: 0.7485, Time on train: 36.33s, Time on val: 13.36s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2846, AUC: 0.7443, Time on train: 36.28s, Time on val: 13.46s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2825, AUC: 0.7528, Time on train: 36.30s, Time on val: 13.38s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2790, AUC: 0.7408, Time on train: 36.24s, Time on val: 13.46s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2822, AUC: 0.7392, Time on train: 36.29s, Time on val: 13.34s\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Learning rate is updated to [5e-05]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2601, AUC: 0.7742, Time on train: 36.18s, Time on val: 13.34s\n",
      "Learning rate is updated to [5e-05]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2597, AUC: 0.7755, Time on train: 36.19s, Time on val: 13.48s\n",
      "Learning rate is updated to [5e-05]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2600, AUC: 0.7754, Time on train: 36.14s, Time on val: 13.66s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [5e-05]\n",
      "Training complete. Best Validation Loss: 0.259724950697273\n",
      "Starting test with batch size = 32 and learning rate = 0.001\n",
      "The final epoch iterations are 256.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.2998, AUC: 0.6155, Time on train: 36.13s, Time on val: 13.42s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3057, AUC: 0.6466, Time on train: 36.20s, Time on val: 13.38s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.2988, AUC: 0.6667, Time on train: 36.18s, Time on val: 13.28s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.3127, AUC: 0.6694, Time on train: 36.17s, Time on val: 13.32s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.2938, AUC: 0.6793, Time on train: 36.31s, Time on val: 13.41s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.2940, AUC: 0.7049, Time on train: 36.34s, Time on val: 13.36s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.2821, AUC: 0.7169, Time on train: 36.21s, Time on val: 13.53s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.2861, AUC: 0.7166, Time on train: 35.86s, Time on val: 13.40s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2861, AUC: 0.7183, Time on train: 36.83s, Time on val: 13.36s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2796, AUC: 0.7310, Time on train: 35.84s, Time on val: 13.50s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2796, AUC: 0.7360, Time on train: 35.84s, Time on val: 13.40s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2835, AUC: 0.7287, Time on train: 35.72s, Time on val: 13.42s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2758, AUC: 0.7435, Time on train: 35.78s, Time on val: 13.44s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2739, AUC: 0.7399, Time on train: 35.77s, Time on val: 13.36s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2764, AUC: 0.7444, Time on train: 35.77s, Time on val: 13.32s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Training complete. Best Validation Loss: 0.2738666738383472\n",
      "Starting test with batch size = 32 and learning rate = 0.01\n",
      "The final epoch iterations are 256.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.3264, AUC: 0.5143, Time on train: 35.78s, Time on val: 13.37s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3152, AUC: 0.5395, Time on train: 35.81s, Time on val: 13.43s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.3051, AUC: 0.5777, Time on train: 35.82s, Time on val: 13.59s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.3101, AUC: 0.5307, Time on train: 35.84s, Time on val: 13.57s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.3227, AUC: 0.5438, Time on train: 35.84s, Time on val: 13.42s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.3202, AUC: 0.5567, Time on train: 35.81s, Time on val: 13.45s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.3039, AUC: 0.5981, Time on train: 35.86s, Time on val: 13.44s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.3102, AUC: 0.5894, Time on train: 35.82s, Time on val: 13.36s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.3039, AUC: 0.5946, Time on train: 35.83s, Time on val: 13.47s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.3064, AUC: 0.6020, Time on train: 36.02s, Time on val: 13.43s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.3237, AUC: 0.6162, Time on train: 35.84s, Time on val: 13.32s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.3026, AUC: 0.6220, Time on train: 35.81s, Time on val: 13.46s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.3015, AUC: 0.6240, Time on train: 35.72s, Time on val: 13.31s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2998, AUC: 0.6266, Time on train: 35.76s, Time on val: 13.50s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2986, AUC: 0.6298, Time on train: 35.81s, Time on val: 13.44s\n",
      "Learning rate is updated to [0.001]\n",
      "Training complete. Best Validation Loss: 0.2986095268279314\n",
      "Starting test with batch size = 32 and learning rate = 0.1\n",
      "The final epoch iterations are 256.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.3119, AUC: 0.5372, Time on train: 35.81s, Time on val: 13.41s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3055, AUC: 0.5518, Time on train: 38.17s, Time on val: 13.21s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.3053, AUC: 0.5761, Time on train: 35.18s, Time on val: 13.17s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.3043, AUC: 0.5855, Time on train: 35.85s, Time on val: 13.49s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.3030, AUC: 0.5842, Time on train: 35.70s, Time on val: 13.49s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.3187, AUC: 0.5202, Time on train: 35.69s, Time on val: 13.31s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.3082, AUC: 0.5802, Time on train: 35.74s, Time on val: 13.24s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.3043, AUC: 0.5905, Time on train: 35.70s, Time on val: 13.21s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.3039, AUC: 0.5873, Time on train: 35.69s, Time on val: 13.19s\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Learning rate is updated to [0.010000000000000002]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.3004, AUC: 0.5966, Time on train: 35.72s, Time on val: 13.39s\n",
      "Learning rate is updated to [0.010000000000000002]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.3004, AUC: 0.6012, Time on train: 35.71s, Time on val: 13.39s\n",
      "Learning rate is updated to [0.010000000000000002]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.3005, AUC: 0.6016, Time on train: 35.85s, Time on val: 13.31s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.010000000000000002]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2998, AUC: 0.6043, Time on train: 35.82s, Time on val: 13.31s\n",
      "Learning rate is updated to [0.010000000000000002]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.3014, AUC: 0.6023, Time on train: 35.82s, Time on val: 13.49s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.010000000000000002]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.3001, AUC: 0.6069, Time on train: 35.77s, Time on val: 13.26s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.010000000000000002]\n",
      "Training complete. Best Validation Loss: 0.2998080899938941\n",
      "Starting test with batch size = 64 and learning rate = 0.0001\n",
      "The final epoch iterations are 128.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.2889, AUC: 0.6956, Time on train: 37.56s, Time on val: 16.03s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.2788, AUC: 0.7259, Time on train: 37.63s, Time on val: 15.87s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.2737, AUC: 0.7342, Time on train: 37.75s, Time on val: 16.06s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.2767, AUC: 0.7411, Time on train: 37.75s, Time on val: 16.04s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.2720, AUC: 0.7440, Time on train: 37.64s, Time on val: 16.03s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.2682, AUC: 0.7498, Time on train: 37.69s, Time on val: 16.11s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.2667, AUC: 0.7586, Time on train: 37.68s, Time on val: 16.15s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.2667, AUC: 0.7602, Time on train: 37.76s, Time on val: 16.21s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2697, AUC: 0.7584, Time on train: 37.68s, Time on val: 16.26s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2648, AUC: 0.7662, Time on train: 37.68s, Time on val: 16.28s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2653, AUC: 0.7634, Time on train: 37.68s, Time on val: 16.17s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2674, AUC: 0.7660, Time on train: 37.75s, Time on val: 16.03s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2707, AUC: 0.7665, Time on train: 37.88s, Time on val: 16.28s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2687, AUC: 0.7686, Time on train: 37.65s, Time on val: 16.09s\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Learning rate is updated to [1e-05]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2594, AUC: 0.7786, Time on train: 37.75s, Time on val: 16.37s\n",
      "Learning rate is updated to [1e-05]\n",
      "Training complete. Best Validation Loss: 0.25936207734048367\n",
      "Starting test with batch size = 64 and learning rate = 0.0005\n",
      "The final epoch iterations are 128.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.2960, AUC: 0.6768, Time on train: 37.46s, Time on val: 15.88s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3011, AUC: 0.6923, Time on train: 37.53s, Time on val: 15.96s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.2948, AUC: 0.7241, Time on train: 37.48s, Time on val: 15.81s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.2900, AUC: 0.7267, Time on train: 37.42s, Time on val: 15.85s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.2787, AUC: 0.7522, Time on train: 37.41s, Time on val: 15.83s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.2745, AUC: 0.7426, Time on train: 37.29s, Time on val: 15.59s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.2712, AUC: 0.7561, Time on train: 37.03s, Time on val: 15.42s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.2778, AUC: 0.7473, Time on train: 37.03s, Time on val: 15.41s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2766, AUC: 0.7553, Time on train: 37.03s, Time on val: 15.60s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2673, AUC: 0.7545, Time on train: 37.16s, Time on val: 15.69s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2698, AUC: 0.7667, Time on train: 37.24s, Time on val: 15.50s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2713, AUC: 0.7621, Time on train: 37.19s, Time on val: 15.73s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2735, AUC: 0.7639, Time on train: 37.15s, Time on val: 15.46s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2725, AUC: 0.7642, Time on train: 37.35s, Time on val: 15.87s\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Learning rate is updated to [5e-05]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2591, AUC: 0.7800, Time on train: 37.26s, Time on val: 15.68s\n",
      "Learning rate is updated to [5e-05]\n",
      "Training complete. Best Validation Loss: 0.2591266198083758\n",
      "Starting test with batch size = 64 and learning rate = 0.001\n",
      "The final epoch iterations are 128.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.3014, AUC: 0.6166, Time on train: 37.30s, Time on val: 15.71s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3076, AUC: 0.6524, Time on train: 37.42s, Time on val: 15.88s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.3075, AUC: 0.6482, Time on train: 37.34s, Time on val: 15.71s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.2884, AUC: 0.7083, Time on train: 37.29s, Time on val: 15.75s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.2987, AUC: 0.7122, Time on train: 37.28s, Time on val: 15.88s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.2913, AUC: 0.7184, Time on train: 37.32s, Time on val: 15.79s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.2924, AUC: 0.7121, Time on train: 37.11s, Time on val: 15.62s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.2765, AUC: 0.7392, Time on train: 37.15s, Time on val: 15.56s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2786, AUC: 0.7337, Time on train: 37.23s, Time on val: 15.73s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2861, AUC: 0.7129, Time on train: 37.20s, Time on val: 15.55s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2786, AUC: 0.7488, Time on train: 37.19s, Time on val: 15.79s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2772, AUC: 0.7367, Time on train: 37.16s, Time on val: 15.82s\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2637, AUC: 0.7645, Time on train: 37.27s, Time on val: 15.55s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2630, AUC: 0.7677, Time on train: 37.24s, Time on val: 15.70s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2622, AUC: 0.7690, Time on train: 37.29s, Time on val: 15.87s\n",
      "Learning rate is updated to [0.0001]\n",
      "Training complete. Best Validation Loss: 0.2621560437604785\n",
      "Starting test with batch size = 64 and learning rate = 0.01\n",
      "The final epoch iterations are 128.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.3062, AUC: 0.5841, Time on train: 37.29s, Time on val: 15.85s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3052, AUC: 0.5917, Time on train: 37.21s, Time on val: 15.77s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.3042, AUC: 0.5996, Time on train: 37.58s, Time on val: 15.74s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.3004, AUC: 0.6159, Time on train: 37.25s, Time on val: 15.77s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.3070, AUC: 0.6055, Time on train: 37.24s, Time on val: 15.70s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.3025, AUC: 0.6180, Time on train: 37.29s, Time on val: 15.75s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.3175, AUC: 0.4867, Time on train: 37.23s, Time on val: 15.60s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.3006, AUC: 0.6140, Time on train: 37.21s, Time on val: 15.91s\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2994, AUC: 0.6155, Time on train: 37.52s, Time on val: 15.94s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2986, AUC: 0.6222, Time on train: 37.27s, Time on val: 15.62s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2980, AUC: 0.6247, Time on train: 37.30s, Time on val: 15.81s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2980, AUC: 0.6260, Time on train: 37.20s, Time on val: 15.87s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2979, AUC: 0.6330, Time on train: 37.28s, Time on val: 15.84s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2974, AUC: 0.6350, Time on train: 37.27s, Time on val: 15.32s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2977, AUC: 0.6351, Time on train: 37.29s, Time on val: 15.80s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Training complete. Best Validation Loss: 0.29743831921368835\n",
      "Starting test with batch size = 64 and learning rate = 0.1\n",
      "The final epoch iterations are 128.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.3078, AUC: 0.5106, Time on train: 37.13s, Time on val: 15.87s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3109, AUC: 0.5104, Time on train: 37.14s, Time on val: 15.47s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.3086, AUC: 0.5274, Time on train: 37.17s, Time on val: 15.71s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.3090, AUC: 0.5360, Time on train: 37.08s, Time on val: 15.58s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.3068, AUC: 0.5712, Time on train: 37.08s, Time on val: 15.60s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.3048, AUC: 0.5481, Time on train: 37.16s, Time on val: 15.71s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.3033, AUC: 0.5756, Time on train: 37.14s, Time on val: 15.79s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.3033, AUC: 0.5823, Time on train: 37.15s, Time on val: 15.68s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.3040, AUC: 0.5928, Time on train: 37.17s, Time on val: 15.70s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.3034, AUC: 0.6011, Time on train: 37.24s, Time on val: 15.79s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.3014, AUC: 0.5976, Time on train: 37.24s, Time on val: 15.75s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.3023, AUC: 0.6007, Time on train: 37.25s, Time on val: 15.77s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.3032, AUC: 0.5931, Time on train: 37.13s, Time on val: 15.81s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.3015, AUC: 0.6048, Time on train: 37.11s, Time on val: 15.61s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.3062, AUC: 0.5933, Time on train: 37.13s, Time on val: 15.71s\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Learning rate is updated to [0.010000000000000002]\n",
      "Training complete. Best Validation Loss: 0.3013532146811485\n"
     ]
    }
   ],
   "source": [
    "# Test each combination of batch size and learning rate\n",
    "for batch_size in [32, 64]:\n",
    "    for lr in learning_rates:\n",
    "        print(f'Starting test with batch size = {batch_size} and learning rate = {lr}')\n",
    "\n",
    "        # Data Loaders\n",
    "        dataloaders, dataset_sizes, class_names = make_data_loaders(train_csv, val_csv, image_dir, batch_size, image_size)\n",
    "\n",
    "        # Model setup\n",
    "        model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "        # Loss function and optimizer\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = get_optimizer(model.parameters(), 'Adam', lr)\n",
    "\n",
    "        final_epoch_iter = iter_per_epoch/batch_size\n",
    "\n",
    "        print(f'The final epoch iterations are {final_epoch_iter}')\n",
    "\n",
    "        # Train the model and log results\n",
    "        model, val_losses, val_aucs, epoch_times = train_model_logs(model, dataloaders['train'], dataloaders['val'], criterion, optimizer, num_epochs, final_epoch_iter)\n",
    "\n",
    "        # Get the index for storing the results in the matrix\n",
    "        batch_index, lr_index = get_index(batch_size, lr)\n",
    "\n",
    "        # Store the final validation loss, mean AUC, and average epoch time\n",
    "        final_val_losses[batch_index, lr_index] = val_losses[-1]  # Final validation loss of the last epoch\n",
    "        final_val_aucs[batch_index, lr_index] = val_aucs[-1]  # Final AUC of the last epoch\n",
    "        epoch_times_matrix[batch_index, lr_index] = np.mean(epoch_times)  # Mean time per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Validation Losses (Rows = Batch Sizes, Cols = Learning Rates):\n",
      "[[0.26252185 0.25995788 0.27644844 0.29860953 0.3001355 ]\n",
      " [0.25936208 0.25912662 0.26215604 0.29766158 0.30616561]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "\n",
      "Final Validation AUCs (Rows = Batch Sizes, Cols = Learning Rates):\n",
      "[[0.77608133 0.77535943 0.74437191 0.62975499 0.60694743]\n",
      " [0.77860174 0.7799702  0.76904186 0.63514585 0.59326952]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "\n",
      "Epoch Times (Rows = Batch Sizes, Cols = Learning Rates):\n",
      "[[25.39302119 24.84496219 24.7286786  24.62969208 24.6039915 ]\n",
      " [26.917045   26.47636538 26.49051169 26.52443393 26.42820734]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the final matrices\n",
    "print(\"\\nFinal Validation Losses (Rows = Batch Sizes, Cols = Learning Rates):\")\n",
    "print(final_val_losses)\n",
    "\n",
    "print(\"\\nFinal Validation AUCs (Rows = Batch Sizes, Cols = Learning Rates):\")\n",
    "print(final_val_aucs)\n",
    "\n",
    "print(\"\\nEpoch Times (Rows = Batch Sizes, Cols = Learning Rates):\")\n",
    "print(epoch_times_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test with batch size = 128 and learning rate = 0.0001\n",
      "The final epoch iterations are 64.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.2988, AUC: 0.6632, Time on train: 37.19s, Time on val: 13.91s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.2828, AUC: 0.7092, Time on train: 37.18s, Time on val: 13.97s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.2754, AUC: 0.7301, Time on train: 36.97s, Time on val: 13.85s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.2763, AUC: 0.7358, Time on train: 37.02s, Time on val: 13.91s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.2732, AUC: 0.7452, Time on train: 37.03s, Time on val: 13.87s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.2801, AUC: 0.7446, Time on train: 37.13s, Time on val: 13.87s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.2709, AUC: 0.7533, Time on train: 37.05s, Time on val: 14.04s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.2677, AUC: 0.7541, Time on train: 37.02s, Time on val: 13.85s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2715, AUC: 0.7583, Time on train: 37.05s, Time on val: 13.90s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2663, AUC: 0.7677, Time on train: 37.03s, Time on val: 13.90s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2683, AUC: 0.7688, Time on train: 37.14s, Time on val: 13.82s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2665, AUC: 0.7652, Time on train: 37.09s, Time on val: 13.92s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2644, AUC: 0.7728, Time on train: 36.86s, Time on val: 13.83s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2644, AUC: 0.7736, Time on train: 36.84s, Time on val: 13.79s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2681, AUC: 0.7733, Time on train: 36.83s, Time on val: 13.80s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Training complete. Best Validation Loss: 0.26438053920865057\n",
      "Starting test with batch size = 128 and learning rate = 0.0005\n",
      "The final epoch iterations are 64.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.2970, AUC: 0.6797, Time on train: 36.98s, Time on val: 13.78s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.2860, AUC: 0.7034, Time on train: 36.82s, Time on val: 13.85s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.3012, AUC: 0.7142, Time on train: 36.78s, Time on val: 13.85s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.2855, AUC: 0.7270, Time on train: 36.78s, Time on val: 13.80s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.2788, AUC: 0.7489, Time on train: 36.95s, Time on val: 13.81s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.2749, AUC: 0.7560, Time on train: 37.00s, Time on val: 13.91s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.2864, AUC: 0.7526, Time on train: 36.85s, Time on val: 13.87s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.3422, AUC: 0.7316, Time on train: 36.78s, Time on val: 13.76s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2696, AUC: 0.7633, Time on train: 36.79s, Time on val: 13.82s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2896, AUC: 0.7569, Time on train: 36.79s, Time on val: 13.78s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2729, AUC: 0.7652, Time on train: 36.73s, Time on val: 13.81s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2854, AUC: 0.7651, Time on train: 36.92s, Time on val: 13.85s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2764, AUC: 0.7610, Time on train: 36.88s, Time on val: 13.84s\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Learning rate is updated to [5e-05]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2587, AUC: 0.7798, Time on train: 36.81s, Time on val: 13.81s\n",
      "Learning rate is updated to [5e-05]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2579, AUC: 0.7812, Time on train: 36.77s, Time on val: 13.80s\n",
      "Learning rate is updated to [5e-05]\n",
      "Training complete. Best Validation Loss: 0.25788602530956267\n",
      "Starting test with batch size = 128 and learning rate = 0.001\n",
      "The final epoch iterations are 64.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.3014, AUC: 0.6521, Time on train: 36.78s, Time on val: 13.83s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3437, AUC: 0.6672, Time on train: 36.83s, Time on val: 13.78s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.3242, AUC: 0.6574, Time on train: 36.82s, Time on val: 13.83s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.2935, AUC: 0.7187, Time on train: 36.84s, Time on val: 13.82s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.2974, AUC: 0.6943, Time on train: 36.72s, Time on val: 13.85s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.2781, AUC: 0.7305, Time on train: 36.68s, Time on val: 13.78s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.2737, AUC: 0.7413, Time on train: 36.70s, Time on val: 13.79s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.2744, AUC: 0.7374, Time on train: 36.82s, Time on val: 13.81s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2782, AUC: 0.7393, Time on train: 36.85s, Time on val: 13.82s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2716, AUC: 0.7474, Time on train: 36.82s, Time on val: 13.83s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2774, AUC: 0.7409, Time on train: 36.72s, Time on val: 13.85s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2765, AUC: 0.7514, Time on train: 36.74s, Time on val: 13.78s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2798, AUC: 0.7461, Time on train: 36.69s, Time on val: 13.72s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2786, AUC: 0.7481, Time on train: 36.81s, Time on val: 13.80s\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2607, AUC: 0.7741, Time on train: 36.66s, Time on val: 13.83s\n",
      "Learning rate is updated to [0.0001]\n",
      "Training complete. Best Validation Loss: 0.2606786582618952\n",
      "Starting test with batch size = 128 and learning rate = 0.01\n",
      "The final epoch iterations are 64.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.3100, AUC: 0.5008, Time on train: 36.73s, Time on val: 13.78s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3154, AUC: 0.5562, Time on train: 36.66s, Time on val: 13.85s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.3102, AUC: 0.5027, Time on train: 36.72s, Time on val: 13.78s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.3063, AUC: 0.5744, Time on train: 36.83s, Time on val: 13.80s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.3174, AUC: 0.5438, Time on train: 36.67s, Time on val: 13.75s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.3124, AUC: 0.5814, Time on train: 36.71s, Time on val: 13.81s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.3024, AUC: 0.6099, Time on train: 36.80s, Time on val: 13.73s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.3143, AUC: 0.5695, Time on train: 36.79s, Time on val: 13.75s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.3013, AUC: 0.6123, Time on train: 36.70s, Time on val: 13.75s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.3092, AUC: 0.5613, Time on train: 36.69s, Time on val: 13.83s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.3037, AUC: 0.6167, Time on train: 36.75s, Time on val: 13.77s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.3056, AUC: 0.6095, Time on train: 36.72s, Time on val: 13.77s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.3149, AUC: 0.5941, Time on train: 36.69s, Time on val: 13.74s\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2983, AUC: 0.6270, Time on train: 36.59s, Time on val: 13.82s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.3009, AUC: 0.6195, Time on train: 36.68s, Time on val: 13.77s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Training complete. Best Validation Loss: 0.2983346313238144\n",
      "Starting test with batch size = 128 and learning rate = 0.1\n",
      "The final epoch iterations are 64.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.3145, AUC: 0.5069, Time on train: 36.62s, Time on val: 13.84s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3068, AUC: 0.5596, Time on train: 36.81s, Time on val: 13.78s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.3048, AUC: 0.5635, Time on train: 36.74s, Time on val: 13.85s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.3032, AUC: 0.5852, Time on train: 36.72s, Time on val: 13.80s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.3040, AUC: 0.5931, Time on train: 36.81s, Time on val: 13.81s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.3038, AUC: 0.6042, Time on train: 36.75s, Time on val: 13.82s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.3018, AUC: 0.6142, Time on train: 36.65s, Time on val: 13.77s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.3024, AUC: 0.6090, Time on train: 36.73s, Time on val: 13.79s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.3111, AUC: 0.5981, Time on train: 36.83s, Time on val: 13.71s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.3016, AUC: 0.6260, Time on train: 36.63s, Time on val: 13.77s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.3106, AUC: 0.6073, Time on train: 36.67s, Time on val: 13.85s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.3313, AUC: 0.5807, Time on train: 36.62s, Time on val: 13.85s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.3062, AUC: 0.6162, Time on train: 36.69s, Time on val: 13.82s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.3023, AUC: 0.5991, Time on train: 36.68s, Time on val: 13.76s\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Learning rate is updated to [0.010000000000000002]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2975, AUC: 0.6318, Time on train: 36.63s, Time on val: 13.77s\n",
      "Learning rate is updated to [0.010000000000000002]\n",
      "Training complete. Best Validation Loss: 0.29752022325992583\n",
      "Starting test with batch size = 256 and learning rate = 0.0001\n",
      "The final epoch iterations are 32.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.3603, AUC: 0.6095, Time on train: 39.39s, Time on val: 14.06s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.2979, AUC: 0.6789, Time on train: 39.42s, Time on val: 21.92s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.2885, AUC: 0.7089, Time on train: 49.22s, Time on val: 13.79s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.2807, AUC: 0.7336, Time on train: 38.07s, Time on val: 13.69s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.2763, AUC: 0.7444, Time on train: 38.03s, Time on val: 13.67s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.2756, AUC: 0.7523, Time on train: 38.07s, Time on val: 13.72s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.2701, AUC: 0.7570, Time on train: 37.98s, Time on val: 13.79s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.2706, AUC: 0.7552, Time on train: 38.06s, Time on val: 13.79s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2745, AUC: 0.7595, Time on train: 38.97s, Time on val: 13.78s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2712, AUC: 0.7665, Time on train: 38.08s, Time on val: 13.76s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2664, AUC: 0.7604, Time on train: 37.99s, Time on val: 13.89s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2678, AUC: 0.7698, Time on train: 38.02s, Time on val: 13.67s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2713, AUC: 0.7635, Time on train: 38.47s, Time on val: 13.74s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2635, AUC: 0.7685, Time on train: 38.02s, Time on val: 13.79s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2637, AUC: 0.7691, Time on train: 38.00s, Time on val: 13.75s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Training complete. Best Validation Loss: 0.2634694017469883\n",
      "Starting test with batch size = 256 and learning rate = 0.0005\n",
      "The final epoch iterations are 32.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.2956, AUC: 0.6958, Time on train: 37.98s, Time on val: 13.76s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.2920, AUC: 0.7169, Time on train: 38.13s, Time on val: 13.78s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.2885, AUC: 0.7394, Time on train: 37.93s, Time on val: 13.56s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.2800, AUC: 0.7361, Time on train: 37.91s, Time on val: 14.22s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.2700, AUC: 0.7558, Time on train: 37.96s, Time on val: 14.40s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.2815, AUC: 0.7531, Time on train: 38.02s, Time on val: 14.72s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.2843, AUC: 0.7476, Time on train: 37.99s, Time on val: 14.57s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.2844, AUC: 0.7585, Time on train: 38.05s, Time on val: 14.12s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2713, AUC: 0.7587, Time on train: 38.00s, Time on val: 14.36s\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "Learning rate is updated to [5e-05]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2599, AUC: 0.7778, Time on train: 37.91s, Time on val: 14.12s\n",
      "Learning rate is updated to [5e-05]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2582, AUC: 0.7814, Time on train: 37.87s, Time on val: 13.70s\n",
      "Learning rate is updated to [5e-05]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2588, AUC: 0.7814, Time on train: 37.90s, Time on val: 13.80s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [5e-05]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2580, AUC: 0.7834, Time on train: 38.10s, Time on val: 14.90s\n",
      "Learning rate is updated to [5e-05]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2584, AUC: 0.7837, Time on train: 38.08s, Time on val: 14.27s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [5e-05]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2583, AUC: 0.7848, Time on train: 37.98s, Time on val: 13.70s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [5e-05]\n",
      "Training complete. Best Validation Loss: 0.25798882767558096\n",
      "Starting test with batch size = 256 and learning rate = 0.001\n",
      "The final epoch iterations are 32.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.3108, AUC: 0.6056, Time on train: 37.89s, Time on val: 13.75s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3028, AUC: 0.6880, Time on train: 37.87s, Time on val: 13.63s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.3535, AUC: 0.6682, Time on train: 37.87s, Time on val: 14.07s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.2890, AUC: 0.7100, Time on train: 38.07s, Time on val: 14.12s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.2809, AUC: 0.7334, Time on train: 37.90s, Time on val: 13.69s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.3133, AUC: 0.7130, Time on train: 37.94s, Time on val: 14.23s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.2840, AUC: 0.7407, Time on train: 37.92s, Time on val: 13.73s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.2786, AUC: 0.7386, Time on train: 37.83s, Time on val: 13.65s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2710, AUC: 0.7512, Time on train: 37.89s, Time on val: 13.76s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2808, AUC: 0.7461, Time on train: 37.92s, Time on val: 13.65s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2734, AUC: 0.7528, Time on train: 37.87s, Time on val: 13.61s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2692, AUC: 0.7628, Time on train: 37.87s, Time on val: 13.59s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2754, AUC: 0.7538, Time on train: 37.78s, Time on val: 14.01s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2862, AUC: 0.7499, Time on train: 37.94s, Time on val: 13.86s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2732, AUC: 0.7643, Time on train: 39.70s, Time on val: 14.27s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.001]\n",
      "Training complete. Best Validation Loss: 0.269162093102932\n",
      "Starting test with batch size = 256 and learning rate = 0.01\n",
      "The final epoch iterations are 32.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 1.2406, AUC: 0.4793, Time on train: 40.16s, Time on val: 14.26s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3067, AUC: 0.5349, Time on train: 39.65s, Time on val: 14.21s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.3081, AUC: 0.5572, Time on train: 39.88s, Time on val: 14.21s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.3068, AUC: 0.5802, Time on train: 39.82s, Time on val: 14.11s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.3057, AUC: 0.5610, Time on train: 39.72s, Time on val: 14.11s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.3242, AUC: 0.5725, Time on train: 39.66s, Time on val: 14.07s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.3019, AUC: 0.5987, Time on train: 39.97s, Time on val: 14.25s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.3067, AUC: 0.5846, Time on train: 40.06s, Time on val: 14.08s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.3025, AUC: 0.6102, Time on train: 40.00s, Time on val: 14.30s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.3017, AUC: 0.6214, Time on train: 39.06s, Time on val: 13.91s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.3019, AUC: 0.6177, Time on train: 38.98s, Time on val: 13.99s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.3060, AUC: 0.6015, Time on train: 38.97s, Time on val: 13.95s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2990, AUC: 0.6243, Time on train: 38.98s, Time on val: 14.02s\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.3001, AUC: 0.6259, Time on train: 38.93s, Time on val: 13.99s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.3092, AUC: 0.5960, Time on train: 38.98s, Time on val: 13.99s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.01]\n",
      "Training complete. Best Validation Loss: 0.2990198373794556\n",
      "Starting test with batch size = 256 and learning rate = 0.1\n",
      "The final epoch iterations are 32.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 16.7923, AUC: 0.4733, Time on train: 39.01s, Time on val: 13.95s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3076, AUC: 0.5251, Time on train: 39.08s, Time on val: 14.03s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.3064, AUC: 0.5274, Time on train: 39.21s, Time on val: 14.09s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.3065, AUC: 0.5270, Time on train: 39.12s, Time on val: 14.06s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.3063, AUC: 0.5346, Time on train: 39.02s, Time on val: 14.49s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.3068, AUC: 0.5241, Time on train: 39.23s, Time on val: 14.51s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.3082, AUC: 0.5312, Time on train: 39.11s, Time on val: 14.82s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.3074, AUC: 0.5279, Time on train: 39.02s, Time on val: 13.93s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.3050, AUC: 0.5274, Time on train: 39.17s, Time on val: 15.20s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.3049, AUC: 0.5584, Time on train: 39.22s, Time on val: 15.41s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.3081, AUC: 0.5479, Time on train: 39.21s, Time on val: 14.53s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.3086, AUC: 0.5532, Time on train: 39.03s, Time on val: 14.58s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.3029, AUC: 0.5903, Time on train: 39.07s, Time on val: 14.88s\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.3050, AUC: 0.5940, Time on train: 39.01s, Time on val: 14.38s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.3077, AUC: 0.5848, Time on train: 39.05s, Time on val: 14.32s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.1]\n",
      "Training complete. Best Validation Loss: 0.30290357619524\n"
     ]
    }
   ],
   "source": [
    "# Test each combination of batch size and learning rate\n",
    "for batch_size in [128, 256]:\n",
    "    for lr in learning_rates:\n",
    "        print(f'Starting test with batch size = {batch_size} and learning rate = {lr}')\n",
    "\n",
    "        # Data Loaders\n",
    "        dataloaders, dataset_sizes, class_names = make_data_loaders(train_csv, val_csv, image_dir, batch_size, image_size)\n",
    "\n",
    "        # Model setup\n",
    "        model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "        # Loss function and optimizer\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = get_optimizer(model.parameters(), 'Adam', lr)\n",
    "\n",
    "        final_epoch_iter = iter_per_epoch/batch_size\n",
    "\n",
    "        print(f'The final epoch iterations are {final_epoch_iter}')\n",
    "\n",
    "        # Train the model and log results\n",
    "        model, val_losses, val_aucs, epoch_times = train_model_logs(model, dataloaders['train'], dataloaders['val'], criterion, optimizer, num_epochs, final_epoch_iter)\n",
    "\n",
    "        # Get the index for storing the results in the matrix\n",
    "        batch_index, lr_index = get_index(batch_size, lr)\n",
    "\n",
    "        # Store the final validation loss, mean AUC, and average epoch time\n",
    "        final_val_losses[batch_index, lr_index] = val_losses[-1]  # Final validation loss of the last epoch\n",
    "        final_val_aucs[batch_index, lr_index] = val_aucs[-1]  # Final AUC of the last epoch\n",
    "        epoch_times_matrix[batch_index, lr_index] = np.mean(epoch_times)  # Mean time per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test with batch size = 512 and learning rate = 0.0001\n",
      "The final epoch iterations are 16.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.4787, AUC: 0.6000, Time on train: 139.73s, Time on val: 25.23s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3288, AUC: 0.6436, Time on train: 133.44s, Time on val: 25.52s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.3029, AUC: 0.6878, Time on train: 133.26s, Time on val: 23.08s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.2881, AUC: 0.7096, Time on train: 130.95s, Time on val: 22.53s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.2843, AUC: 0.7281, Time on train: 130.64s, Time on val: 22.13s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.2786, AUC: 0.7372, Time on train: 128.55s, Time on val: 22.15s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.2772, AUC: 0.7478, Time on train: 128.52s, Time on val: 22.21s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.2740, AUC: 0.7493, Time on train: 128.37s, Time on val: 22.20s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2716, AUC: 0.7523, Time on train: 137.44s, Time on val: 22.94s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2720, AUC: 0.7551, Time on train: 130.33s, Time on val: 22.79s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2686, AUC: 0.7608, Time on train: 130.59s, Time on val: 22.61s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2670, AUC: 0.7597, Time on train: 132.11s, Time on val: 22.93s\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2693, AUC: 0.7638, Time on train: 130.19s, Time on val: 22.35s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2725, AUC: 0.7610, Time on train: 129.49s, Time on val: 22.30s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0001]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2664, AUC: 0.7652, Time on train: 134.40s, Time on val: 22.62s\n",
      "Learning rate is updated to [0.0001]\n",
      "Training complete. Best Validation Loss: 0.2664340794086456\n",
      "Starting test with batch size = 512 and learning rate = 0.0005\n",
      "The final epoch iterations are 16.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.3023, AUC: 0.6538, Time on train: 137.40s, Time on val: 20.37s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.2880, AUC: 0.7053, Time on train: 137.44s, Time on val: 20.64s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 3/15\n",
      "Epoch [3/15], Validation Loss: 0.2812, AUC: 0.7287, Time on train: 139.05s, Time on val: 20.58s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 4/15\n",
      "Epoch [4/15], Validation Loss: 0.3156, AUC: 0.7230, Time on train: 138.55s, Time on val: 20.72s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 5/15\n",
      "Epoch [5/15], Validation Loss: 0.2988, AUC: 0.7334, Time on train: 138.20s, Time on val: 20.50s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 6/15\n",
      "Epoch [6/15], Validation Loss: 0.2760, AUC: 0.7413, Time on train: 138.01s, Time on val: 20.46s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 7/15\n",
      "Epoch [7/15], Validation Loss: 0.2795, AUC: 0.7380, Time on train: 138.33s, Time on val: 20.96s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 8/15\n",
      "Epoch [8/15], Validation Loss: 0.2707, AUC: 0.7559, Time on train: 138.15s, Time on val: 20.55s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 9/15\n",
      "Epoch [9/15], Validation Loss: 0.2879, AUC: 0.7578, Time on train: 137.80s, Time on val: 20.36s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 10/15\n",
      "Epoch [10/15], Validation Loss: 0.2720, AUC: 0.7585, Time on train: 137.47s, Time on val: 20.55s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 11/15\n",
      "Epoch [11/15], Validation Loss: 0.2713, AUC: 0.7593, Time on train: 137.73s, Time on val: 20.53s\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 12/15\n",
      "Epoch [12/15], Validation Loss: 0.2704, AUC: 0.7634, Time on train: 138.09s, Time on val: 20.76s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 13/15\n",
      "Epoch [13/15], Validation Loss: 0.2671, AUC: 0.7705, Time on train: 138.56s, Time on val: 20.58s\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 14/15\n",
      "Epoch [14/15], Validation Loss: 0.2870, AUC: 0.7645, Time on train: 140.40s, Time on val: 20.97s\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Starting epoch 15/15\n",
      "Epoch [15/15], Validation Loss: 0.2804, AUC: 0.7654, Time on train: 138.36s, Time on val: 20.76s\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "Learning rate is updated to [0.0005]\n",
      "Training complete. Best Validation Loss: 0.2671129912137985\n",
      "Starting test with batch size = 512 and learning rate = 0.001\n",
      "The final epoch iterations are 16.0\n",
      "Starting epoch 1/15\n",
      "Epoch [1/15], Validation Loss: 0.4435, AUC: 0.5615, Time on train: 138.13s, Time on val: 20.68s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 2/15\n",
      "Epoch [2/15], Validation Loss: 0.3210, AUC: 0.6038, Time on train: 141.86s, Time on val: 20.85s\n",
      "Learning rate is updated to [0.001]\n",
      "Starting epoch 3/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe final epoch iterations are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_epoch_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Train the model and log results\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m model, val_losses, val_aucs, epoch_times \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_epoch_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Get the index for storing the results in the matrix\u001b[39;00m\n\u001b[0;32m     26\u001b[0m batch_index, lr_index \u001b[38;5;241m=\u001b[39m get_index(batch_size, lr)\n",
      "Cell \u001b[1;32mIn[15], line 48\u001b[0m, in \u001b[0;36mtrain_model_logs\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, steps, patience)\u001b[0m\n\u001b[0;32m     45\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     46\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 48\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m elapsed_time_train \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time  \u001b[38;5;66;03m# Calculate elapsed time\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Validation at the end of each epoch\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test each combination of batch size and learning rate\n",
    "for batch_size in [512]:\n",
    "    for lr in learning_rates:\n",
    "        print(f'Starting test with batch size = {batch_size} and learning rate = {lr}')\n",
    "\n",
    "        # Data Loaders\n",
    "        dataloaders, dataset_sizes, class_names = make_data_loaders(train_csv, val_csv, image_dir, batch_size, image_size)\n",
    "\n",
    "        # Model setup\n",
    "        model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "        # Loss function and optimizer\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = get_optimizer(model.parameters(), 'Adam', lr)\n",
    "\n",
    "        final_epoch_iter = iter_per_epoch/batch_size\n",
    "\n",
    "        print(f'The final epoch iterations are {final_epoch_iter}')\n",
    "\n",
    "        # Train the model and log results\n",
    "        model, val_losses, val_aucs, epoch_times = train_model_logs(model, dataloaders['train'], dataloaders['val'], criterion, optimizer, num_epochs, final_epoch_iter)\n",
    "\n",
    "        # Get the index for storing the results in the matrix\n",
    "        batch_index, lr_index = get_index(batch_size, lr)\n",
    "\n",
    "        # Store the final validation loss, mean AUC, and average epoch time\n",
    "        final_val_losses[batch_index, lr_index] = val_losses[-1]  # Final validation loss of the last epoch\n",
    "        final_val_aucs[batch_index, lr_index] = val_aucs[-1]  # Final AUC of the last epoch\n",
    "        epoch_times_matrix[batch_index, lr_index] = np.mean(epoch_times)  # Mean time per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Validation Losses (Rows = Batch Sizes, Cols = Learning Rates):\n",
      "[[0.26252185 0.25995788 0.27644844 0.29860953 0.3001355 ]\n",
      " [0.25936208 0.25912662 0.26215604 0.29766158 0.30616561]\n",
      " [0.26810881 0.25788603 0.26067866 0.30087965 0.29752022]\n",
      " [0.26368599 0.25827368 0.27317169 0.30924169 0.30772749]\n",
      " [0.26643408 0.28038959 0.         0.         0.        ]]\n",
      "\n",
      "Final Validation AUCs (Rows = Batch Sizes, Cols = Learning Rates):\n",
      "[[0.77608133 0.77535943 0.74437191 0.62975499 0.60694743]\n",
      " [0.77860174 0.7799702  0.76904186 0.63514585 0.59326952]\n",
      " [0.77327528 0.7811672  0.77411067 0.61950049 0.63177046]\n",
      " [0.76910866 0.784767   0.76427423 0.59600613 0.58475343]\n",
      " [0.76524005 0.76541212 0.         0.         0.        ]]\n",
      "\n",
      "Epoch Times (Rows = Batch Sizes, Cols = Learning Rates):\n",
      "[[25.39302119 24.84496219 24.7286786  24.62969208 24.6039915 ]\n",
      " [26.917045   26.47636538 26.49051169 26.52443393 26.42820734]\n",
      " [25.45546039 25.33268441 25.28565635 25.24761877 25.25345044]\n",
      " [26.68738052 26.05931303 25.92976635 26.80886478 26.79130971]\n",
      " [77.38692597 79.42798235  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the final matrices\n",
    "print(\"\\nFinal Validation Losses (Rows = Batch Sizes, Cols = Learning Rates):\")\n",
    "print(final_val_losses)\n",
    "\n",
    "print(\"\\nFinal Validation AUCs (Rows = Batch Sizes, Cols = Learning Rates):\")\n",
    "print(final_val_aucs)\n",
    "\n",
    "print(\"\\nEpoch Times (Rows = Batch Sizes, Cols = Learning Rates):\")\n",
    "print(epoch_times_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test with image size = 256\n",
      "The final epoch iterations are 16.0\n",
      "Starting epoch 1/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe final epoch iterations are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_epoch_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Train the model and log results\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m model, val_losses, val_aucs, epoch_times \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_per_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m final_val_losses\u001b[38;5;241m.\u001b[39mappend(val_losses)\n\u001b[0;32m     54\u001b[0m final_val_aucs\u001b[38;5;241m.\u001b[39mappend(val_aucs)\n",
      "Cell \u001b[1;32mIn[15], line 48\u001b[0m, in \u001b[0;36mtrain_model_logs\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, steps, patience)\u001b[0m\n\u001b[0;32m     45\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     46\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 48\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m elapsed_time_train \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time  \u001b[38;5;66;03m# Calculate elapsed time\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Validation at the end of each epoch\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "learning_rate = 5e-4\n",
    "num_epochs = 10\n",
    "iter_per_epoch = 500\n",
    "image_sizes = [256,224,128,64]\n",
    "num_classes = 14\n",
    "\n",
    "# Paths\n",
    "train_csv = './labels/train_metadata_positive.csv'\n",
    "val_csv = './labels/val_metadata_positive.csv'\n",
    "image_dir = '../resized_images'\n",
    "\n",
    "# Storage matrices\n",
    "final_val_losses = []\n",
    "final_val_aucs = []\n",
    "final_epoch_times = []\n",
    "\n",
    "# Function to map batch_size and lr indices\n",
    "def get_index(batch_size, lr):\n",
    "    batch_index = batch_sizes.index(batch_size)\n",
    "    lr_index = learning_rates.index(lr)\n",
    "    return batch_index, lr_index\n",
    "\n",
    "# Test each combination of batch size and learning rate\n",
    "for image_size in image_sizes:\n",
    "    print(f'Starting test with image size = {image_size}')\n",
    "\n",
    "    # Data Loaders\n",
    "    dataloaders, dataset_sizes, class_names = make_data_loaders(train_csv, val_csv, image_dir, batch_size, image_size)\n",
    "\n",
    "    # Model setup\n",
    "    model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = get_optimizer(model.parameters(), 'Adam', learning_rate)\n",
    "\n",
    "    # Train the model and log results\n",
    "    model, val_losses, val_aucs, epoch_times = train_model_logs(model, dataloaders['train'], dataloaders['val'], criterion, optimizer, num_epochs, iter_per_epoch)\n",
    "\n",
    "    final_val_losses.append(val_losses)\n",
    "    final_val_aucs.append(val_aucs)\n",
    "    final_epoch_times.append(epoch_times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
